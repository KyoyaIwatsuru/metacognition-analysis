{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Correction Pipeline\n",
    "\n",
    "Click-Anchored Correction（クリック参照点ベース補正）を使用して視線データを補正する。\n",
    "\n",
    "## 概要\n",
    "\n",
    "**アルゴリズム**:\n",
    "1. `choice_click`イベント時刻の視線位置と、クリックした選択肢の`choice_bbox`中心座標のずれを参照点として抽出\n",
    "2. セグメント（問題）ごとに補正パラメータを推定（参照点が不足する場合は前後から補間）\n",
    "3. 補正を適用してAOIマッチ率を検証\n",
    "\n",
    "## 期待される改善\n",
    "- 補正前: 40-60% AOI内率\n",
    "- 補正後: 75-90% AOI内率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../lib')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import eyegaze as eg\n",
    "\n",
    "# データディレクトリ\n",
    "DATA_INPUT = '../../data/input'\n",
    "DATA_WORKING = '../../data/working'\n",
    "OUTPUT_BASE = os.path.join(DATA_WORKING, 'corrections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 単一参加者でテスト (P001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参加者とフェーズの設定\n",
    "GROUP = 'B'\n",
    "PARTICIPANT = 'P019'\n",
    "PHASE = 'pre'\n",
    "\n",
    "# 座標データは同じグループのTestから取得（個人データでは欠損がある場合があるため）\n",
    "COORD_PARTICIPANT = 'Test'\n",
    "\n",
    "# AOIマッチング許容値（ピクセル）\n",
    "# 文間スペース12pxを考慮し、重ならない範囲で設定\n",
    "TOLERANCE = 5.0  # 上下5pxずつ拡大 → 合計10px < 12px\n",
    "\n",
    "# スケーリング重視モード設定\n",
    "# - prefer_scaling=True: スケーリングを優先し、オフセットは残差から計算\n",
    "# - max_offset=20.0: オフセットを±20px以内に制限\n",
    "# → 右側ボタンで計算したオフセットが左側テキストに不適切に適用される問題を回避\n",
    "\n",
    "# パス設定（視線データ・ログ・背景画像は個人データを使用）\n",
    "participant_dir = os.path.join(DATA_INPUT, GROUP, PARTICIPANT, PHASE)\n",
    "eye_tracking_dirs = glob(os.path.join(participant_dir, 'eye_tracking', '*'))\n",
    "eye_tracking_dir = eye_tracking_dirs[0] if eye_tracking_dirs else None\n",
    "\n",
    "event_log_files = glob(os.path.join(participant_dir, 'logs', 'events_*.jsonl'))\n",
    "event_log_path = event_log_files[0] if event_log_files else None\n",
    "\n",
    "# 座標データは同じグループのTestから取得\n",
    "coord_dir = os.path.join(DATA_INPUT, GROUP, COORD_PARTICIPANT, PHASE, 'coordinates')\n",
    "\n",
    "print(f\"Eye tracking dir: {eye_tracking_dir}\")\n",
    "print(f\"Event log: {event_log_path}\")\n",
    "print(f\"Coordinates dir: {coord_dir} (from {GROUP}/{COORD_PARTICIPANT})\")\n",
    "print(f\"Tolerance: {TOLERANCE}px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 補正パイプラインを実行\n",
    "output_dir = os.path.join(OUTPUT_BASE, GROUP, PARTICIPANT, PHASE)\n",
    "\n",
    "result = eg.runClickAnchoredCorrection(\n",
    "    eye_tracking_dir=eye_tracking_dir,\n",
    "    event_log_path=event_log_path,\n",
    "    coord_dir=coord_dir,\n",
    "    phase=PHASE,\n",
    "    window_before_ms=200,\n",
    "    window_after_ms=50,\n",
    "    min_samples=5,\n",
    "    outlier_threshold_px=300,\n",
    "    output_dir=output_dir,\n",
    "    tolerance=TOLERANCE,\n",
    "    prefer_scaling=True,     # スケーリング重視モード\n",
    "    max_offset=20.0,         # オフセット制限（±20px）\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参照点データを確認\n",
    "ref_points = result['reference_points']\n",
    "print(f\"参照点数: {len(ref_points)}\")\n",
    "ref_points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セグメント補正値を確認\n",
    "seg_corrections = result['segment_corrections']\n",
    "print(f\"セグメント数: {len(seg_corrections)}\")\n",
    "seg_corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証結果を確認\n",
    "validation = pd.DataFrame(result['validation_results'])\n",
    "print(f\"検証セグメント数: {len(validation)}\")\n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 補正効果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 補正前後のAOI内率を比較\n",
    "if len(validation) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 棒グラフ: セグメントごとのAOI内率\n",
    "    x = np.arange(len(validation))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0].bar(x - width/2, validation['original_rate'], width, label='Original', alpha=0.7)\n",
    "    axes[0].bar(x + width/2, validation['corrected_rate'], width, label='Corrected', alpha=0.7)\n",
    "    axes[0].set_xlabel('Segment Index')\n",
    "    axes[0].set_ylabel('AOI Rate')\n",
    "    axes[0].set_title('AOI Rate by Segment')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(validation['segment_id'], rotation=45, ha='right')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    \n",
    "    # 改善率のヒストグラム\n",
    "    axes[1].hist(validation['improvement'], bins=10, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(x=0, color='red', linestyle='--', label='No improvement')\n",
    "    axes[1].axvline(x=validation['improvement'].mean(), color='green', linestyle='-', label=f'Mean: {validation[\"improvement\"].mean():.3f}')\n",
    "    axes[1].set_xlabel('Improvement')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Distribution of AOI Rate Improvement')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No validation results to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オフセット分布の可視化\n",
    "if len(ref_points) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # オフセットの散布図\n",
    "    axes[0].scatter(ref_points['offset_x'], ref_points['offset_y'], alpha=0.6)\n",
    "    axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[0].axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_xlabel('Offset X (px)')\n",
    "    axes[0].set_ylabel('Offset Y (px)')\n",
    "    axes[0].set_title('Reference Point Offsets')\n",
    "    \n",
    "    # オフセットのヒストグラム\n",
    "    offset_mag = np.sqrt(ref_points['offset_x']**2 + ref_points['offset_y']**2)\n",
    "    axes[1].hist(offset_mag, bins=15, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(x=offset_mag.mean(), color='red', linestyle='--', label=f'Mean: {offset_mag.mean():.1f} px')\n",
    "    axes[1].set_xlabel('Offset Magnitude (px)')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Distribution of Offset Magnitudes')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No reference points to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特定セグメントの補正前後比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOI Rate計算に使用するレベル（画面上の全要素を対象）\n",
    "# paragraph/wordはsentenceと重複するため除外\n",
    "AOI_LEVELS = [\n",
    "    'instruction',   # 問題指示文\n",
    "    'sentence',      # 本文（文単位）\n",
    "    'question',      # 問題文\n",
    "    'choice',        # 選択肢\n",
    "    'timer',         # タイマー\n",
    "    'ui',            # UIボタン等\n",
    "    'header',        # ヘッダー\n",
    "    'reflection',    # リフレクション入力欄\n",
    "    'title',         # パッセージタイトル\n",
    "    'subtitle',      # サブタイトル\n",
    "    'intro',         # イントロ\n",
    "    'analog',        # 類題関連\n",
    "    'metadata',      # メタデータ（送信者、日付等）\n",
    "    'table',         # 表\n",
    "    'explanation',   # 解説\n",
    "    'metacog'        # メタ認知支援解説\n",
    "]\n",
    "\n",
    "# 固視点の表示サイズ（固定値）\n",
    "FIXATION_SIZE = 50\n",
    "\n",
    "# 特定のセグメントを可視化\n",
    "def visualize_correction(segment_id, eye_tracking_dir, event_log_path, coord_dir,\n",
    "                         segment_corrections, phase='pre', tolerance=0.0,\n",
    "                         scale_x=None, scale_y=None, offset_x=None, offset_y=None):\n",
    "    \"\"\"セグメントの補正前後を可視化\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    segment_id : str\n",
    "        対象セグメントID\n",
    "    eye_tracking_dir : str\n",
    "        視線データディレクトリ\n",
    "    event_log_path : str\n",
    "        イベントログファイルパス\n",
    "    coord_dir : str\n",
    "        座標定義ディレクトリ\n",
    "    segment_corrections : pd.DataFrame\n",
    "        セグメント補正パラメータ（segment_id, scale_x, scale_y, offset_x, offset_y）\n",
    "    phase : str\n",
    "        実験フェーズ\n",
    "    tolerance : float\n",
    "        AOI境界からの許容距離（ピクセル）\n",
    "    scale_x, scale_y : float, optional\n",
    "        明示的なスケーリング値（指定時はsegment_correctionsより優先）\n",
    "    offset_x, offset_y : float, optional\n",
    "        明示的なオフセット値（指定時はsegment_correctionsより優先）\n",
    "    \"\"\"\n",
    "    # セグメントを読み込み\n",
    "    segments = eg.readTobiiData(eye_tracking_dir, event_log_path, phase=phase)\n",
    "    seg = [s for s in segments if s.get('passage_id') == segment_id]\n",
    "    if not seg:\n",
    "        print(f\"Segment {segment_id} not found\")\n",
    "        return\n",
    "    seg = seg[0]\n",
    "\n",
    "    data = seg['data']\n",
    "    image_path = seg.get('image_path', '')\n",
    "\n",
    "    # AOIを読み込み\n",
    "    coord_files = [f for f in os.listdir(coord_dir) if f.startswith(f'question_{segment_id}')]\n",
    "    if not coord_files:\n",
    "        print(f\"Coordinates for {segment_id} not found\")\n",
    "        return\n",
    "    coord_path = os.path.join(coord_dir, coord_files[0])\n",
    "    coordinates = eg.loadCoordinates(coord_path)\n",
    "    \n",
    "    # 画像ファイル名からAOI抽出パラメータを取得\n",
    "    aoi_params = {}\n",
    "    if image_path:\n",
    "        parsed = eg.parseImageFilename(image_path)\n",
    "        if parsed:\n",
    "            aoi_params = {\n",
    "                'target_locale': parsed['target_locale'],\n",
    "                'target_question': parsed['target_question'],\n",
    "                'target_analog': parsed['target_analog'],\n",
    "            }\n",
    "    \n",
    "    aois = eg.extractAllAOIs(coordinates, levels=AOI_LEVELS, **aoi_params)\n",
    "\n",
    "    # Fixationを検出\n",
    "    times, X, Y, P = data[:, 0], data[:, 1], data[:, 2], data[:, 3]\n",
    "    fixations = eg.detectFixations(times, X, Y, P)\n",
    "\n",
    "    if len(fixations) == 0:\n",
    "        print(\"No fixations detected\")\n",
    "        return\n",
    "\n",
    "    # 補正パラメータを取得（明示的引数があればそれを優先）\n",
    "    if scale_x is None or scale_y is None or offset_x is None or offset_y is None:\n",
    "        correction = segment_corrections[segment_corrections['segment_id'] == segment_id]\n",
    "        if correction.empty:\n",
    "            sx, sy = 1.0, 1.0\n",
    "            ox, oy = 0.0, 0.0\n",
    "        else:\n",
    "            sx = correction['scale_x'].iloc[0] if 'scale_x' in correction.columns else 1.0\n",
    "            sy = correction['scale_y'].iloc[0] if 'scale_y' in correction.columns else 1.0\n",
    "            ox = correction['offset_x'].iloc[0] or 0\n",
    "            oy = correction['offset_y'].iloc[0] or 0\n",
    "        # 明示的引数で上書き\n",
    "        scale_x = scale_x if scale_x is not None else sx\n",
    "        scale_y = scale_y if scale_y is not None else sy\n",
    "        offset_x = offset_x if offset_x is not None else ox\n",
    "        offset_y = offset_y if offset_y is not None else oy\n",
    "\n",
    "    # 補正を適用\n",
    "    corrected_fixations = eg.applyScalingAndOffset(fixations, scale_x, scale_y, offset_x, offset_y)\n",
    "\n",
    "    # 可視化\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "\n",
    "    for ax, fix_data, title in [(axes[0], fixations, 'Original'),\n",
    "                                 (axes[1], corrected_fixations, 'Corrected')]:\n",
    "        # 背景画像\n",
    "        if os.path.exists(image_path):\n",
    "            img = plt.imread(image_path)\n",
    "            ax.imshow(img)\n",
    "\n",
    "        # AOI領域を描画\n",
    "        import matplotlib.patches as patches\n",
    "        for aoi in aois:\n",
    "            if aoi.get('is_multiline') and 'bboxes' in aoi:\n",
    "                for bbox in aoi['bboxes']:\n",
    "                    # tolerance > 0 の場合、拡大領域を薄い色で表示\n",
    "                    if tolerance > 0:\n",
    "                        expanded_rect = patches.Rectangle(\n",
    "                            (bbox['x'] - tolerance, bbox['y'] - tolerance),\n",
    "                            bbox['width'] + 2 * tolerance,\n",
    "                            bbox['height'] + 2 * tolerance,\n",
    "                            linewidth=1, edgecolor='lightgreen', facecolor='lightgreen', alpha=0.2\n",
    "                        )\n",
    "                        ax.add_patch(expanded_rect)\n",
    "                    # 元の枠\n",
    "                    rect = patches.Rectangle(\n",
    "                        (bbox['x'], bbox['y']), bbox['width'], bbox['height'],\n",
    "                        linewidth=1, edgecolor='green', facecolor='none', alpha=0.5\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "            else:\n",
    "                bbox = aoi['bbox']\n",
    "                # tolerance > 0 の場合、拡大領域を薄い色で表示\n",
    "                if tolerance > 0:\n",
    "                    expanded_rect = patches.Rectangle(\n",
    "                        (bbox['x'] - tolerance, bbox['y'] - tolerance),\n",
    "                        bbox['width'] + 2 * tolerance,\n",
    "                        bbox['height'] + 2 * tolerance,\n",
    "                        linewidth=1, edgecolor='lightgreen', facecolor='lightgreen', alpha=0.2\n",
    "                    )\n",
    "                    ax.add_patch(expanded_rect)\n",
    "                # 元の枠\n",
    "                rect = patches.Rectangle(\n",
    "                    (bbox['x'], bbox['y']), bbox['width'], bbox['height'],\n",
    "                    linewidth=1, edgecolor='green', facecolor='none', alpha=0.5\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "        # Fixationを描画（固定サイズ）\n",
    "        fx, fy = fix_data[:, 1], fix_data[:, 2]\n",
    "        ax.scatter(fx, fy, s=FIXATION_SIZE, c='red', alpha=0.6, edgecolors='darkred', linewidths=0.5)\n",
    "\n",
    "        # AOI内率を計算（tolerance適用）\n",
    "        rate_info = eg.computeAllAOIRate(fix_data, aois, tolerance=tolerance)\n",
    "\n",
    "        ax.set_xlim(0, 1920)\n",
    "        ax.set_ylim(1080, 0)\n",
    "        ax.set_title(f'{title} - AOI Rate: {rate_info[\"rate\"]:.3f} ({rate_info[\"fixations_in_aoi\"]}/{rate_info[\"total_fixations\"]})')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(f'Segment: {segment_id} | Scale: ({scale_x:.3f}, {scale_y:.3f}) | Offset: ({offset_x:.1f}, {offset_y:.1f}) px | Tolerance: {tolerance}px', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Scale applied: ({scale_x:.3f}, {scale_y:.3f})\")\n",
    "    print(f\"Offset applied: ({offset_x:.1f}, {offset_y:.1f}) px\")\n",
    "    print(f\"Tolerance: {tolerance}px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初のセグメントを可視化\n",
    "if len(validation) > 0:\n",
    "    first_segment = validation.iloc[1]['segment_id']\n",
    "    visualize_correction(\n",
    "        first_segment, \n",
    "        eye_tracking_dir, \n",
    "        event_log_path, \n",
    "        coord_dir,\n",
    "        seg_corrections,\n",
    "        phase=PHASE,\n",
    "        tolerance=TOLERANCE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 2段階補正アルゴリズム\n",
    "\n",
    "クリック参照点が右側パネル（選択肢・ボタン）に偏っている問題を解決するため、2段階補正を実装する。\n",
    "\n",
    "### アプローチ\n",
    "1. **第1段階（Click-Anchored）**: 既存のクリック参照点ベース補正で大まかなパラメータを推定\n",
    "2. **第2段階（AOI Rate最適化）**: 第1段階の結果を初期値として、AOI Rate最大化でグリッドサーチにより微調整\n",
    "\n",
    "### パラメータ探索範囲（第2段階）\n",
    "- X方向オフセット: ±20px（狭い範囲で微調整）\n",
    "- Y方向オフセット: ±30px\n",
    "- Y軸スケーリング: 0.90〜1.30（拡大を許容）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_stage_correction(segment_id, eye_tracking_dir, event_log_path, coord_dir,\n",
    "                         stage1_corrections, phase='pre', tolerance=0.0,\n",
    "                         stage2_search_x=(-20, 20), stage2_search_y=(-30, 30),\n",
    "                         stage2_scale_range=(0.90, 1.30),\n",
    "                         offset_step=5, scale_step=0.02,\n",
    "                         verbose=True):\n",
    "    \"\"\"\n",
    "    2段階補正を実行\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    segment_id : str\n",
    "        対象セグメントID\n",
    "    eye_tracking_dir : str\n",
    "        視線データディレクトリ\n",
    "    event_log_path : str\n",
    "        イベントログファイルパス\n",
    "    coord_dir : str\n",
    "        座標定義ディレクトリ\n",
    "    stage1_corrections : pd.DataFrame\n",
    "        第1段階の補正パラメータ（runClickAnchoredCorrectionの結果）\n",
    "    phase : str\n",
    "        実験フェーズ\n",
    "    tolerance : float\n",
    "        AOI境界からの許容距離（ピクセル）\n",
    "    stage2_search_x, stage2_search_y : tuple\n",
    "        第2段階のオフセット探索範囲\n",
    "    stage2_scale_range : tuple\n",
    "        第2段階のスケーリング探索範囲（Y軸）\n",
    "    offset_step : int\n",
    "        オフセットの探索刻み幅\n",
    "    scale_step : float\n",
    "        スケーリングの探索刻み幅\n",
    "    verbose : bool\n",
    "        詳細出力\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        {\n",
    "            \"segment_id\": str,\n",
    "            \"original_fixations\": np.ndarray,\n",
    "            \"stage1_fixations\": np.ndarray,\n",
    "            \"stage2_fixations\": np.ndarray,\n",
    "            \"stage1_params\": dict,\n",
    "            \"stage2_params\": dict,\n",
    "            \"final_params\": dict,\n",
    "            \"original_rate\": float,\n",
    "            \"stage1_rate\": float,\n",
    "            \"stage2_rate\": float,\n",
    "            \"aois\": list,\n",
    "            \"image_path\": str\n",
    "        }\n",
    "    \"\"\"\n",
    "    # セグメントを読み込み\n",
    "    segments = eg.readTobiiData(eye_tracking_dir, event_log_path, phase=phase)\n",
    "    seg = [s for s in segments if s.get('passage_id') == segment_id]\n",
    "    if not seg:\n",
    "        print(f\"Segment {segment_id} not found\")\n",
    "        return None\n",
    "    seg = seg[0]\n",
    "\n",
    "    data = seg['data']\n",
    "    image_path = seg.get('image_path', '')\n",
    "\n",
    "    # AOIを読み込み\n",
    "    coord_files = [f for f in os.listdir(coord_dir) if f.startswith(f'question_{segment_id}')]\n",
    "    if not coord_files:\n",
    "        print(f\"Coordinates for {segment_id} not found\")\n",
    "        return None\n",
    "    coord_path = os.path.join(coord_dir, coord_files[0])\n",
    "    coordinates = eg.loadCoordinates(coord_path)\n",
    "    \n",
    "    # 画像ファイル名からAOI抽出パラメータを取得\n",
    "    aoi_params = {}\n",
    "    if image_path:\n",
    "        parsed = eg.parseImageFilename(image_path)\n",
    "        if parsed:\n",
    "            aoi_params = {\n",
    "                'target_locale': parsed['target_locale'],\n",
    "                'target_question': parsed['target_question'],\n",
    "                'target_analog': parsed['target_analog'],\n",
    "            }\n",
    "    \n",
    "    aois = eg.extractAllAOIs(coordinates, levels=AOI_LEVELS, **aoi_params)\n",
    "\n",
    "    # Fixationを検出\n",
    "    times, X, Y, P = data[:, 0], data[:, 1], data[:, 2], data[:, 3]\n",
    "    fixations = eg.detectFixations(times, X, Y, P)\n",
    "\n",
    "    if len(fixations) == 0:\n",
    "        print(\"No fixations detected\")\n",
    "        return None\n",
    "\n",
    "    # オリジナルのAOI Rate\n",
    "    original_rate_info = eg.computeAllAOIRate(fixations, aois, tolerance=tolerance)\n",
    "    original_rate = original_rate_info['rate']\n",
    "\n",
    "    # --- 第1段階: Click-Anchored補正パラメータを取得 ---\n",
    "    correction = stage1_corrections[stage1_corrections['segment_id'] == segment_id]\n",
    "    if correction.empty:\n",
    "        s1_scale_x, s1_scale_y = 1.0, 1.0\n",
    "        s1_offset_x, s1_offset_y = 0.0, 0.0\n",
    "    else:\n",
    "        s1_scale_x = correction['scale_x'].iloc[0] if 'scale_x' in correction.columns else 1.0\n",
    "        s1_scale_y = correction['scale_y'].iloc[0] if 'scale_y' in correction.columns else 1.0\n",
    "        s1_offset_x = correction['offset_x'].iloc[0] or 0\n",
    "        s1_offset_y = correction['offset_y'].iloc[0] or 0\n",
    "\n",
    "    # 第1段階の補正を適用\n",
    "    stage1_fixations = eg.applyScalingAndOffset(\n",
    "        fixations, s1_scale_x, s1_scale_y, s1_offset_x, s1_offset_y\n",
    "    )\n",
    "    stage1_rate_info = eg.computeAllAOIRate(stage1_fixations, aois, tolerance=tolerance)\n",
    "    stage1_rate = stage1_rate_info['rate']\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"=== {segment_id} ===\")\n",
    "        print(f\"Stage 1 (Click-Anchored):\")\n",
    "        print(f\"  Scale: ({s1_scale_x:.3f}, {s1_scale_y:.3f})\")\n",
    "        print(f\"  Offset: ({s1_offset_x:.1f}, {s1_offset_y:.1f}) px\")\n",
    "        print(f\"  AOI Rate: {original_rate:.3f} -> {stage1_rate:.3f} ({stage1_rate - original_rate:+.3f})\")\n",
    "\n",
    "    # --- 第2段階: AOI Rate最適化による微調整 ---\n",
    "    # 第1段階補正後のデータに対してグリッドサーチ\n",
    "    stage2_result = eg.estimateOffsetWithScaling(\n",
    "        stage1_fixations, aois,\n",
    "        search_range_x=stage2_search_x,\n",
    "        search_range_y=stage2_search_y,\n",
    "        scale_range=stage2_scale_range,\n",
    "        offset_step=offset_step,\n",
    "        scale_step=scale_step,\n",
    "        tolerance=tolerance,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    s2_scale_x = stage2_result['best_scale_x']\n",
    "    s2_scale_y = stage2_result['best_scale_y']\n",
    "    s2_offset_x = stage2_result['best_offset_x']\n",
    "    s2_offset_y = stage2_result['best_offset_y']\n",
    "\n",
    "    # 第2段階の補正を適用（第1段階の結果に対して）\n",
    "    stage2_fixations = eg.applyScalingAndOffset(\n",
    "        stage1_fixations, s2_scale_x, s2_scale_y, s2_offset_x, s2_offset_y\n",
    "    )\n",
    "    stage2_rate_info = eg.computeAllAOIRate(stage2_fixations, aois, tolerance=tolerance)\n",
    "    stage2_rate = stage2_rate_info['rate']\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Stage 2 (AOI Rate Optimization):\")\n",
    "        print(f\"  Scale: ({s2_scale_x:.3f}, {s2_scale_y:.3f})\")\n",
    "        print(f\"  Offset: ({s2_offset_x:.1f}, {s2_offset_y:.1f}) px\")\n",
    "        print(f\"  AOI Rate: {stage1_rate:.3f} -> {stage2_rate:.3f} ({stage2_rate - stage1_rate:+.3f})\")\n",
    "\n",
    "    # 最終パラメータを計算（2段階の合成）\n",
    "    # 変換式: x' = s2_scale_x * (s1_scale_x * (x - cx) + cx + s1_offset_x - cx) + cx + s2_offset_x\n",
    "    # 簡略化: final_scale = s1 * s2, final_offset = s2_scale * s1_offset + s2_offset\n",
    "    final_scale_x = s1_scale_x * s2_scale_x\n",
    "    final_scale_y = s1_scale_y * s2_scale_y\n",
    "    final_offset_x = s2_scale_x * s1_offset_x + s2_offset_x\n",
    "    final_offset_y = s2_scale_y * s1_offset_y + s2_offset_y\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Final (Combined):\")\n",
    "        print(f\"  Scale: ({final_scale_x:.3f}, {final_scale_y:.3f})\")\n",
    "        print(f\"  Offset: ({final_offset_x:.1f}, {final_offset_y:.1f}) px\")\n",
    "        print(f\"  Total Improvement: {original_rate:.3f} -> {stage2_rate:.3f} ({stage2_rate - original_rate:+.3f})\")\n",
    "\n",
    "    return {\n",
    "        \"segment_id\": segment_id,\n",
    "        \"original_fixations\": fixations,\n",
    "        \"stage1_fixations\": stage1_fixations,\n",
    "        \"stage2_fixations\": stage2_fixations,\n",
    "        \"stage1_params\": {\n",
    "            \"scale_x\": s1_scale_x, \"scale_y\": s1_scale_y,\n",
    "            \"offset_x\": s1_offset_x, \"offset_y\": s1_offset_y\n",
    "        },\n",
    "        \"stage2_params\": {\n",
    "            \"scale_x\": s2_scale_x, \"scale_y\": s2_scale_y,\n",
    "            \"offset_x\": s2_offset_x, \"offset_y\": s2_offset_y\n",
    "        },\n",
    "        \"final_params\": {\n",
    "            \"scale_x\": final_scale_x, \"scale_y\": final_scale_y,\n",
    "            \"offset_x\": final_offset_x, \"offset_y\": final_offset_y\n",
    "        },\n",
    "        \"original_rate\": original_rate,\n",
    "        \"stage1_rate\": stage1_rate,\n",
    "        \"stage2_rate\": stage2_rate,\n",
    "        \"aois\": aois,\n",
    "        \"image_path\": image_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_two_stage(result, tolerance=0.0, save_path=None, show=True):\n",
    "    \"\"\"\n",
    "    2段階補正の結果を3パネルで可視化\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    result : dict\n",
    "        two_stage_correctionの返り値\n",
    "    tolerance : float\n",
    "        AOI境界からの許容距離（ピクセル）\n",
    "    save_path : str, optional\n",
    "        画像保存先パス（指定時は保存）\n",
    "    show : bool\n",
    "        Trueの場合plt.show()で表示（バッチ処理時はFalseに）\n",
    "    \"\"\"\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    if result is None:\n",
    "        print(\"No result to visualize\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(27, 9))\n",
    "\n",
    "    data_list = [\n",
    "        (result['original_fixations'], 'Original', result['original_rate']),\n",
    "        (result['stage1_fixations'], 'Stage 1 (Click-Anchored)', result['stage1_rate']),\n",
    "        (result['stage2_fixations'], 'Stage 2 (AOI Optimized)', result['stage2_rate'])\n",
    "    ]\n",
    "\n",
    "    aois = result['aois']\n",
    "    image_path = result['image_path']\n",
    "\n",
    "    for ax, (fix_data, title, rate) in zip(axes, data_list):\n",
    "        # 背景画像\n",
    "        if os.path.exists(image_path):\n",
    "            img = plt.imread(image_path)\n",
    "            ax.imshow(img)\n",
    "\n",
    "        # AOI領域を描画\n",
    "        for aoi in aois:\n",
    "            if aoi.get('is_multiline') and 'bboxes' in aoi:\n",
    "                for bbox in aoi['bboxes']:\n",
    "                    if tolerance > 0:\n",
    "                        expanded_rect = patches.Rectangle(\n",
    "                            (bbox['x'] - tolerance, bbox['y'] - tolerance),\n",
    "                            bbox['width'] + 2 * tolerance,\n",
    "                            bbox['height'] + 2 * tolerance,\n",
    "                            linewidth=1, edgecolor='lightgreen', facecolor='lightgreen', alpha=0.2\n",
    "                        )\n",
    "                        ax.add_patch(expanded_rect)\n",
    "                    rect = patches.Rectangle(\n",
    "                        (bbox['x'], bbox['y']), bbox['width'], bbox['height'],\n",
    "                        linewidth=1, edgecolor='green', facecolor='none', alpha=0.5\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "            else:\n",
    "                bbox = aoi['bbox']\n",
    "                if tolerance > 0:\n",
    "                    expanded_rect = patches.Rectangle(\n",
    "                        (bbox['x'] - tolerance, bbox['y'] - tolerance),\n",
    "                        bbox['width'] + 2 * tolerance,\n",
    "                        bbox['height'] + 2 * tolerance,\n",
    "                        linewidth=1, edgecolor='lightgreen', facecolor='lightgreen', alpha=0.2\n",
    "                    )\n",
    "                    ax.add_patch(expanded_rect)\n",
    "                rect = patches.Rectangle(\n",
    "                    (bbox['x'], bbox['y']), bbox['width'], bbox['height'],\n",
    "                    linewidth=1, edgecolor='green', facecolor='none', alpha=0.5\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "        # Fixationを描画（固定サイズ）\n",
    "        fx, fy = fix_data[:, 1], fix_data[:, 2]\n",
    "        ax.scatter(fx, fy, s=FIXATION_SIZE, c='red', alpha=0.6, edgecolors='darkred', linewidths=0.5)\n",
    "\n",
    "        ax.set_xlim(0, 1920)\n",
    "        ax.set_ylim(1080, 0)\n",
    "        n_fix = len(fix_data)\n",
    "        n_in_aoi = int(rate * n_fix)\n",
    "        ax.set_title(f'{title}\\nAOI Rate: {rate:.3f} ({n_in_aoi}/{n_fix})', fontsize=12)\n",
    "        ax.axis('off')\n",
    "\n",
    "    # 全体タイトル\n",
    "    s1 = result['stage1_params']\n",
    "    s2 = result['stage2_params']\n",
    "    final = result['final_params']\n",
    "    plt.suptitle(\n",
    "        f\"Segment: {result['segment_id']} | Tolerance: {tolerance}px\\n\"\n",
    "        f\"Stage1: scale=({s1['scale_x']:.3f}, {s1['scale_y']:.3f}), offset=({s1['offset_x']:.1f}, {s1['offset_y']:.1f})\\n\"\n",
    "        f\"Stage2: scale=({s2['scale_x']:.3f}, {s2['scale_y']:.3f}), offset=({s2['offset_x']:.1f}, {s2['offset_y']:.1f})\\n\"\n",
    "        f\"Final: scale=({final['scale_x']:.3f}, {final['scale_y']:.3f}), offset=({final['offset_x']:.1f}, {final['offset_y']:.1f})\",\n",
    "        fontsize=11\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "    if show:\n",
    "        # 改善サマリー\n",
    "        print(f\"\\n=== Improvement Summary ===\")\n",
    "        print(f\"Original -> Stage1: {result['original_rate']:.3f} -> {result['stage1_rate']:.3f} ({result['stage1_rate'] - result['original_rate']:+.3f})\")\n",
    "        print(f\"Stage1 -> Stage2: {result['stage1_rate']:.3f} -> {result['stage2_rate']:.3f} ({result['stage2_rate'] - result['stage1_rate']:+.3f})\")\n",
    "        print(f\"Total: {result['original_rate']:.3f} -> {result['stage2_rate']:.3f} ({result['stage2_rate'] - result['original_rate']:+.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2段階補正をpre_01セグメントでテスト\n",
    "test_segment = 'pre_01'\n",
    "two_stage_result = two_stage_correction(\n",
    "    segment_id=test_segment,\n",
    "    eye_tracking_dir=eye_tracking_dir,\n",
    "    event_log_path=event_log_path,\n",
    "    coord_dir=coord_dir,\n",
    "    stage1_corrections=seg_corrections,\n",
    "    phase=PHASE,\n",
    "    tolerance=TOLERANCE,\n",
    "    stage2_search_x=(-20, 20),\n",
    "    stage2_search_y=(-30, 30),\n",
    "    stage2_scale_range=(0.90, 1.30),\n",
    "    offset_step=5,\n",
    "    scale_step=0.02,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3パネルで可視化\n",
    "if two_stage_result:\n",
    "    visualize_two_stage(two_stage_result, tolerance=TOLERANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全セグメントで2段階補正を実行し、Stage1のみ vs 2段階補正を比較\n",
    "all_two_stage_results = []\n",
    "\n",
    "for segment_id in seg_corrections['segment_id']:\n",
    "    result = two_stage_correction(\n",
    "        segment_id=segment_id,\n",
    "        eye_tracking_dir=eye_tracking_dir,\n",
    "        event_log_path=event_log_path,\n",
    "        coord_dir=coord_dir,\n",
    "        stage1_corrections=seg_corrections,\n",
    "        phase=PHASE,\n",
    "        tolerance=TOLERANCE,\n",
    "        stage2_search_x=(-20, 20),\n",
    "        stage2_search_y=(-30, 30),\n",
    "        stage2_scale_range=(0.90, 1.30),\n",
    "        offset_step=5,\n",
    "        scale_step=0.02,\n",
    "        verbose=False\n",
    "    )\n",
    "    if result:\n",
    "        all_two_stage_results.append({\n",
    "            'segment_id': segment_id,\n",
    "            'original_rate': result['original_rate'],\n",
    "            'stage1_rate': result['stage1_rate'],\n",
    "            'stage2_rate': result['stage2_rate'],\n",
    "            'stage1_improvement': result['stage1_rate'] - result['original_rate'],\n",
    "            'stage2_improvement': result['stage2_rate'] - result['stage1_rate'],\n",
    "            'total_improvement': result['stage2_rate'] - result['original_rate'],\n",
    "            **{f's1_{k}': v for k, v in result['stage1_params'].items()},\n",
    "            **{f's2_{k}': v for k, v in result['stage2_params'].items()},\n",
    "            **{f'final_{k}': v for k, v in result['final_params'].items()}\n",
    "        })\n",
    "\n",
    "two_stage_df = pd.DataFrame(all_two_stage_results)\n",
    "print(\"=== 2段階補正サマリー ===\")\n",
    "print(f\"平均Original Rate: {two_stage_df['original_rate'].mean():.3f}\")\n",
    "print(f\"平均Stage1 Rate: {two_stage_df['stage1_rate'].mean():.3f} (平均改善: {two_stage_df['stage1_improvement'].mean():+.3f})\")\n",
    "print(f\"平均Stage2 Rate: {two_stage_df['stage2_rate'].mean():.3f} (平均改善: {two_stage_df['stage2_improvement'].mean():+.3f})\")\n",
    "print(f\"合計改善: {two_stage_df['total_improvement'].mean():+.3f}\")\n",
    "print()\n",
    "two_stage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2段階補正の効果を可視化\n",
    "if len(two_stage_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # 棒グラフ: セグメントごとのAOI Rate比較（Original, Stage1, Stage2）\n",
    "    x = np.arange(len(two_stage_df))\n",
    "    width = 0.25\n",
    "\n",
    "    axes[0].bar(x - width, two_stage_df['original_rate'], width, label='Original', alpha=0.7)\n",
    "    axes[0].bar(x, two_stage_df['stage1_rate'], width, label='Stage 1', alpha=0.7)\n",
    "    axes[0].bar(x + width, two_stage_df['stage2_rate'], width, label='Stage 2', alpha=0.7)\n",
    "    axes[0].set_xlabel('Segment')\n",
    "    axes[0].set_ylabel('AOI Rate')\n",
    "    axes[0].set_title('AOI Rate Comparison: Original vs Stage1 vs Stage2')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(two_stage_df['segment_id'], rotation=45, ha='right')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_ylim(0, 1)\n",
    "\n",
    "    # Stage1のみ vs 2段階補正の改善率比較\n",
    "    axes[1].bar(x - width/2, two_stage_df['stage1_improvement'], width, label='Stage1 Improvement', alpha=0.7, color='orange')\n",
    "    axes[1].bar(x + width/2, two_stage_df['total_improvement'], width, label='Total (Stage1+2) Improvement', alpha=0.7, color='green')\n",
    "    axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_xlabel('Segment')\n",
    "    axes[1].set_ylabel('Improvement')\n",
    "    axes[1].set_title('Improvement: Stage1 Only vs 2-Stage Correction')\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(two_stage_df['segment_id'], rotation=45, ha='right')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Stage1で悪化したセグメントがStage2で改善されたかを確認\n",
    "    degraded_in_s1 = two_stage_df[two_stage_df['stage1_improvement'] < 0]\n",
    "    if len(degraded_in_s1) > 0:\n",
    "        print(\"\\n=== Stage1で悪化したセグメント ===\")\n",
    "        for _, row in degraded_in_s1.iterrows():\n",
    "            recovered = \"改善\" if row['total_improvement'] > row['stage1_improvement'] else \"未改善\"\n",
    "            print(f\"  {row['segment_id']}: Stage1 {row['stage1_improvement']:+.3f} -> Total {row['total_improvement']:+.3f} ({recovered})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 全参加者にバッチ適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全参加者リスト\n",
    "PARTICIPANTS = {\n",
    "    'A': ['P001', 'P002', 'P005', 'P006', 'P008', 'P009', 'P010', 'P011', 'P016', 'P017'],\n",
    "    'B': ['P003', 'P004', 'P007', 'P012', 'P013', 'P014', 'P015', 'P018', 'P019', 'P020']\n",
    "}\n",
    "\n",
    "# 全フェーズ\n",
    "PHASES = ['pre', 'training1', 'training2', 'training3', 'post']\n",
    "\n",
    "print(f\"A群: {len(PARTICIPANTS['A'])}名\")\n",
    "print(f\"B群: {len(PARTICIPANTS['B'])}名\")\n",
    "print(f\"フェーズ: {PHASES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_correction(groups, phases, data_input, output_base, \n",
    "                         tolerance=5.0, prefer_scaling=True, max_offset=20.0,\n",
    "                         coord_participant='Test',\n",
    "                         verbose=False):\n",
    "    \"\"\"全参加者・全フェーズに補正を適用\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    groups : dict\n",
    "        グループごとの参加者リスト {'A': ['P001', ...], 'B': [...]}\n",
    "    phases : list\n",
    "        処理するフェーズのリスト ['pre', 'post', ...]\n",
    "    data_input : str\n",
    "        入力データのベースディレクトリ\n",
    "    output_base : str\n",
    "        出力先のベースディレクトリ\n",
    "    tolerance : float\n",
    "        AOIマッチング許容値（ピクセル）\n",
    "    prefer_scaling : bool\n",
    "        スケーリング優先モード\n",
    "    max_offset : float\n",
    "        オフセット制限値\n",
    "    coord_participant : str\n",
    "        座標データを取得する参加者ID（デフォルト: 'Test'）\n",
    "    verbose : bool\n",
    "        詳細出力\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        全参加者・全フェーズの補正結果サマリー\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    all_segment_corrections = []  # 全セグメントの補正パラメータを収集\n",
    "    \n",
    "    for group, participants in groups.items():\n",
    "        for participant in participants:\n",
    "            for phase in phases:\n",
    "                print(f\"Processing {group}/{participant}/{phase}...\")\n",
    "                \n",
    "                # パス設定（視線データ・ログは個人データ）\n",
    "                participant_dir = os.path.join(data_input, group, participant, phase)\n",
    "                if not os.path.exists(participant_dir):\n",
    "                    print(f\"  Directory not found: {participant_dir}\")\n",
    "                    continue\n",
    "                \n",
    "                eye_tracking_dirs = glob(os.path.join(participant_dir, 'eye_tracking', '*'))\n",
    "                event_log_files = glob(os.path.join(participant_dir, 'logs', 'events_*.jsonl'))\n",
    "                \n",
    "                # 座標データは同じグループのTestから取得\n",
    "                coord_dir = os.path.join(data_input, group, coord_participant, phase, 'coordinates')\n",
    "                \n",
    "                if not eye_tracking_dirs or not event_log_files:\n",
    "                    print(f\"  Missing data files\")\n",
    "                    continue\n",
    "                \n",
    "                if not os.path.exists(coord_dir):\n",
    "                    print(f\"  Coordinates not found: {coord_dir}\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    output_dir = os.path.join(output_base, group, participant, phase)\n",
    "                    result = eg.runClickAnchoredCorrection(\n",
    "                        eye_tracking_dir=eye_tracking_dirs[0],\n",
    "                        event_log_path=event_log_files[0],\n",
    "                        coord_dir=coord_dir,\n",
    "                        phase=phase,\n",
    "                        output_dir=output_dir,\n",
    "                        tolerance=tolerance,\n",
    "                        prefer_scaling=prefer_scaling,\n",
    "                        max_offset=max_offset,\n",
    "                        verbose=verbose\n",
    "                    )\n",
    "                    \n",
    "                    # サマリー情報を追加\n",
    "                    summary = result['summary']\n",
    "                    summary['group'] = group\n",
    "                    summary['participant'] = participant\n",
    "                    summary['phase'] = phase\n",
    "                    all_results.append(summary)\n",
    "                    \n",
    "                    # セグメント補正パラメータを収集\n",
    "                    seg_corr = result['segment_corrections'].copy()\n",
    "                    seg_corr['group'] = group\n",
    "                    seg_corr['participant'] = participant\n",
    "                    seg_corr['phase'] = phase\n",
    "                    all_segment_corrections.append(seg_corr)\n",
    "                    \n",
    "                    print(f\"  Original: {summary['mean_original_rate']:.3f} -> Corrected: {summary['mean_corrected_rate']:.3f} (Improvement: {summary['mean_improvement']:+.3f})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  Error: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "    \n",
    "    # 全セグメント補正パラメータを結合\n",
    "    if all_segment_corrections:\n",
    "        all_corrections_df = pd.concat(all_segment_corrections, ignore_index=True)\n",
    "    else:\n",
    "        all_corrections_df = pd.DataFrame()\n",
    "    \n",
    "    return pd.DataFrame(all_results), all_corrections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ実行：全参加者・全フェーズの補正パラメータを取得\n",
    "print(\"=== バッチ補正を実行中 ===\")\n",
    "print(f\"グループ: {list(PARTICIPANTS.keys())}\")\n",
    "print(f\"フェーズ: {PHASES}\")\n",
    "print(f\"座標データ: 各グループのTestを使用\")\n",
    "print(f\"Tolerance: {TOLERANCE}px\")\n",
    "print()\n",
    "\n",
    "batch_summary, all_corrections = run_batch_correction(\n",
    "    PARTICIPANTS, \n",
    "    PHASES, \n",
    "    DATA_INPUT, \n",
    "    OUTPUT_BASE,\n",
    "    tolerance=TOLERANCE,\n",
    "    prefer_scaling=True,\n",
    "    max_offset=20.0,\n",
    "    coord_participant='Test',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=== 処理完了 ===\")\n",
    "print(f\"処理した参加者×フェーズ: {len(batch_summary)}件\")\n",
    "print(f\"セグメント補正パラメータ: {len(all_corrections)}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をCSVに保存\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "# 1. サマリー（参加者×フェーズごとの平均AOI Rate）\n",
    "summary_path = os.path.join(OUTPUT_BASE, 'batch_summary.csv')\n",
    "batch_summary.to_csv(summary_path, index=False)\n",
    "print(f\"サマリー保存: {summary_path}\")\n",
    "\n",
    "# 2. 全セグメントの補正パラメータ\n",
    "corrections_path = os.path.join(OUTPUT_BASE, 'all_segment_corrections.csv')\n",
    "all_corrections.to_csv(corrections_path, index=False)\n",
    "print(f\"補正パラメータ保存: {corrections_path}\")\n",
    "\n",
    "print()\n",
    "print(\"=== 保存した補正パラメータの列 ===\")\n",
    "print(all_corrections.columns.tolist())\n",
    "print()\n",
    "print(\"=== サンプルデータ（最初の5行） ===\")\n",
    "all_corrections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ結果のサマリー統計\n",
    "print(\"=== グループ×フェーズ別の平均AOI Rate ===\")\n",
    "summary_stats = batch_summary.groupby(['group', 'phase']).agg({\n",
    "    'mean_original_rate': 'mean',\n",
    "    'mean_corrected_rate': 'mean',\n",
    "    'mean_improvement': 'mean'\n",
    "}).round(3)\n",
    "print(summary_stats)\n",
    "\n",
    "print()\n",
    "print(\"=== 全体サマリー ===\")\n",
    "print(f\"平均Original Rate: {batch_summary['mean_original_rate'].mean():.3f}\")\n",
    "print(f\"平均Corrected Rate: {batch_summary['mean_corrected_rate'].mean():.3f}\")\n",
    "print(f\"平均改善率: {batch_summary['mean_improvement'].mean():+.3f}\")\n",
    "\n",
    "# 補正パラメータの統計\n",
    "print()\n",
    "print(\"=== 補正パラメータの統計 ===\")\n",
    "param_stats = all_corrections[['scale_x', 'scale_y', 'offset_x', 'offset_y']].describe().round(3)\n",
    "print(param_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_visualizations_parallel(groups, phases, data_input, output_base, \n",
    "                                        all_corrections_df, tolerance=5.0, \n",
    "                                        coord_participant='Test',\n",
    "                                        n_workers=80):\n",
    "    \"\"\"\n",
    "    全参加者・全セグメントの3パネル画像を並列処理で保存\n",
    "    \n",
    "    eyegaze.py の process_segment_worker を使用\n",
    "    セグメントデータと座標パスを事前に読み込み、引数で渡すことで高速化\n",
    "    \"\"\"\n",
    "    from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    image_dir = os.path.join(output_base, 'visualizations')\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. 全タスクのリストを作成\n",
    "    tasks = []\n",
    "    \n",
    "    for group, participants in groups.items():\n",
    "        for participant in participants:\n",
    "            for phase in phases:\n",
    "                # パス設定\n",
    "                participant_dir = os.path.join(data_input, group, participant, phase)\n",
    "                if not os.path.exists(participant_dir):\n",
    "                    continue\n",
    "                \n",
    "                eye_tracking_dirs = glob(os.path.join(participant_dir, 'eye_tracking', '*'))\n",
    "                event_log_files = glob(os.path.join(participant_dir, 'logs', 'events_*.jsonl'))\n",
    "                coord_dir = os.path.join(data_input, group, coord_participant, phase, 'coordinates')\n",
    "                \n",
    "                if not eye_tracking_dirs or not event_log_files or not os.path.exists(coord_dir):\n",
    "                    continue\n",
    "                \n",
    "                # この参加者・フェーズの補正パラメータを取得\n",
    "                participant_corrections = all_corrections_df[\n",
    "                    (all_corrections_df['group'] == group) &\n",
    "                    (all_corrections_df['participant'] == participant) &\n",
    "                    (all_corrections_df['phase'] == phase)\n",
    "                ]\n",
    "                \n",
    "                if participant_corrections.empty:\n",
    "                    continue\n",
    "                \n",
    "                # セグメントを1回だけ読み込み（高速化のポイント1）\n",
    "                segments = eg.readTobiiData(\n",
    "                    eye_tracking_dirs[0], event_log_files[0], phase=phase\n",
    "                )\n",
    "                \n",
    "                # 座標マッピングを1回だけ作成（高速化のポイント2）\n",
    "                coord_mapping = eg.buildCoordinateMapping(coord_dir)\n",
    "                \n",
    "                # 各セグメントをタスクとして追加\n",
    "                for _, row in participant_corrections.iterrows():\n",
    "                    segment_id = row['segment_id']\n",
    "                    segment_index = int(row['segment_index'])\n",
    "                    \n",
    "                    # segment_indexでセグメントを取得\n",
    "                    if segment_index >= len(segments):\n",
    "                        continue\n",
    "                    seg = segments[segment_index]\n",
    "                    segment_data = seg['data']\n",
    "                    image_path = seg.get('image_path', '')\n",
    "                    \n",
    "                    # マッピングから座標パスを取得（複合キーを使用）\n",
    "                    event_type = row.get('event_type', '')\n",
    "                    prefix = eg._eventTypeToCoordPrefix(event_type)\n",
    "                    coord_path = coord_mapping.get((prefix, segment_id))\n",
    "                    # intro/complete画面はseg_id=Noneでマップされているのでフォールバック\n",
    "                    if not coord_path and prefix in ('training_intro', 'analog_intro', 'training_complete'):\n",
    "                        coord_path = coord_mapping.get((prefix, None))\n",
    "                    \n",
    "                    # segment_idがNoneの場合はevent_typeを使用（intro/complete画面）\n",
    "                    name_part = segment_id if segment_id else event_type\n",
    "                    save_path = os.path.join(\n",
    "                        image_dir, group, participant, phase,\n",
    "                        f'{segment_index:02d}_{name_part}_correction.png'\n",
    "                    )\n",
    "                    \n",
    "                    # 補正パラメータをdictに変換\n",
    "                    correction_dict = row.to_dict()\n",
    "                    \n",
    "                    # eyegaze.py の process_segment_worker 用の引数タプル\n",
    "                    # segment_data, image_path, coord_path を直接渡す\n",
    "                    task_args = (\n",
    "                        segment_index,\n",
    "                        segment_id,\n",
    "                        segment_data,\n",
    "                        image_path,\n",
    "                        coord_path,         # 座標パス（マッピングから取得）\n",
    "                        correction_dict,\n",
    "                        tolerance,\n",
    "                        save_path,\n",
    "                        AOI_LEVELS,\n",
    "                        FIXATION_SIZE\n",
    "                    )\n",
    "                    tasks.append(task_args)\n",
    "    \n",
    "    print(f\"=== 並列処理を開始 ===\")\n",
    "    print(f\"総タスク数: {len(tasks)}\")\n",
    "    print(f\"ワーカー数: {n_workers}\")\n",
    "    print()\n",
    "    \n",
    "    # 2. 並列実行（eyegaze.pyのワーカー関数を使用）\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    errors = []\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {executor.submit(eg.process_segment_worker, task): task for task in tasks}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing segments\"):\n",
    "            result = future.result()\n",
    "            if result['success']:\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "                errors.append(f\"{result['segment_id']}: {result['error']}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"=== 完了 ===\")\n",
    "    print(f\"保存先: {image_dir}\")\n",
    "    print(f\"成功: {success_count}/{len(tasks)}\")\n",
    "    print(f\"エラー: {error_count}\")\n",
    "    \n",
    "    if errors and len(errors) <= 10:\n",
    "        print(\"\\nエラー詳細:\")\n",
    "        for err in errors[:10]:\n",
    "            print(f\"  - {err[:100]}...\")\n",
    "    elif errors:\n",
    "        print(f\"\\n最初の10件のエラー:\")\n",
    "        for err in errors[:10]:\n",
    "            print(f\"  - {err[:100]}...\")\n",
    "    \n",
    "    return image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3パネル画像をバッチ保存（並列処理版）\n",
    "# all_correctionsが存在する場合のみ実行\n",
    "if 'all_corrections' in dir() and len(all_corrections) > 0:\n",
    "    print(\"=== 3パネル画像のバッチ保存（並列処理） ===\")\n",
    "    print(f\"対象: {len(all_corrections)}セグメント\")\n",
    "    print(f\"M3の8コアを活用して並列処理します\")\n",
    "    print()\n",
    "    \n",
    "    viz_dir = save_batch_visualizations_parallel(\n",
    "        PARTICIPANTS, \n",
    "        PHASES, \n",
    "        DATA_INPUT, \n",
    "        OUTPUT_BASE,\n",
    "        all_corrections,\n",
    "        tolerance=TOLERANCE,\n",
    "        coord_participant='Test',\n",
    "        n_workers=80  # M3 8コアなら6ワーカーが最適\n",
    "    )\n",
    "else:\n",
    "    print(\"先にcell-24, cell-25を実行して補正パラメータを取得してください\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 結果サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ結果がある場合の可視化\n",
    "batch_summary_path = os.path.join(OUTPUT_BASE, 'batch_summary.csv')\n",
    "if os.path.exists(batch_summary_path):\n",
    "    batch_results = pd.read_csv(batch_summary_path)\n",
    "    \n",
    "    # グループ別の比較\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for phase in batch_results['phase'].unique():\n",
    "        phase_data = batch_results[batch_results['phase'] == phase]\n",
    "        \n",
    "        # 箱ひげ図: グループ別AOI内率\n",
    "        group_a = phase_data[phase_data['group'] == 'A']['mean_corrected_rate']\n",
    "        group_b = phase_data[phase_data['group'] == 'B']['mean_corrected_rate']\n",
    "        \n",
    "    axes[0].boxplot([batch_results[batch_results['group'] == 'A']['mean_original_rate'],\n",
    "                     batch_results[batch_results['group'] == 'A']['mean_corrected_rate'],\n",
    "                     batch_results[batch_results['group'] == 'B']['mean_original_rate'],\n",
    "                     batch_results[batch_results['group'] == 'B']['mean_corrected_rate']],\n",
    "                    labels=['A-Original', 'A-Corrected', 'B-Original', 'B-Corrected'])\n",
    "    axes[0].set_ylabel('AOI Rate')\n",
    "    axes[0].set_title('AOI Rate Distribution by Group')\n",
    "    \n",
    "    # 改善率のヒストグラム\n",
    "    axes[1].hist(batch_results['mean_improvement'], bins=15, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1].axvline(x=batch_results['mean_improvement'].mean(), color='green', linestyle='-',\n",
    "                    label=f'Mean: {batch_results[\"mean_improvement\"].mean():.3f}')\n",
    "    axes[1].set_xlabel('Improvement')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Distribution of AOI Rate Improvement (All)')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # サマリー統計\n",
    "    print(\"\\n=== Summary Statistics ===\")\n",
    "    print(batch_results.groupby('group')[['mean_original_rate', 'mean_corrected_rate', 'mean_improvement']].mean())\n",
    "else:\n",
    "    print(\"No batch results found. Run the batch correction first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
