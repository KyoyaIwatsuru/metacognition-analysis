{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スコア集計\n",
    "\n",
    "各フェーズ（pre, training1-3, post）の正答数・正答率を集計します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロジェクトルート\n",
    "project_root = Path.cwd().parent.parent\n",
    "base_dir = project_root / \"data\" / \"input\"\n",
    "print(f\"データディレクトリ: {base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スコア抽出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scores(base_dir: Path) -> dict:\n",
    "    \"\"\"\n",
    "    ログファイルからスコアを抽出する\n",
    "    \"\"\"\n",
    "    data = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    for group_dir in base_dir.iterdir():\n",
    "        if not group_dir.is_dir():\n",
    "            continue\n",
    "        group = group_dir.name\n",
    "\n",
    "        for participant_dir in group_dir.iterdir():\n",
    "            if not participant_dir.is_dir():\n",
    "                continue\n",
    "            participant = participant_dir.name\n",
    "\n",
    "            # Pre系・Test系参加者（テスト用）はスキップ\n",
    "            if participant.startswith(\"Pre\") or participant.startswith(\"Test\"):\n",
    "                continue\n",
    "\n",
    "            for phase_dir in participant_dir.iterdir():\n",
    "                if not phase_dir.is_dir():\n",
    "                    continue\n",
    "                phase = phase_dir.name\n",
    "\n",
    "                logs_dir = phase_dir / \"logs\"\n",
    "                if not logs_dir.exists():\n",
    "                    continue\n",
    "\n",
    "                for log_file in logs_dir.glob(\"*.jsonl\"):\n",
    "                    correct_total = 0\n",
    "                    question_total = 0\n",
    "\n",
    "                    with open(log_file, \"r\") as f:\n",
    "                        for line in f:\n",
    "                            line = line.strip()\n",
    "                            if not line:\n",
    "                                continue\n",
    "                            try:\n",
    "                                event = json.loads(line)\n",
    "                                if event.get(\"event\") == \"answer_submit\":\n",
    "                                    correct_total += event.get(\"correct_count\", 0)\n",
    "                                    question_total += event.get(\"total_count\", 0)\n",
    "                                elif event.get(\"event\") == \"analog_answer_submit\":\n",
    "                                    correct_total += event.get(\"correct_count\", 0)\n",
    "                                    question_total += event.get(\"total_count\", 0)\n",
    "                            except json.JSONDecodeError:\n",
    "                                pass\n",
    "\n",
    "                    if question_total > 0:\n",
    "                        data[group][participant][phase] = {\n",
    "                            \"correct\": correct_total,\n",
    "                            \"total\": question_total,\n",
    "                            \"rate\": correct_total / question_total * 100,\n",
    "                        }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = extract_scores(base_dir)\n",
    "print(f\"グループ数: {len(data)}\")\n",
    "for g in sorted(data.keys()):\n",
    "    print(f\"  グループ {g}: {len(data[g])}名\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参加者別スコア一覧\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score_dataframe(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    スコアデータをDataFrameに変換\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    phases = [\"pre\", \"training1\", \"training2\", \"training3\", \"post\"]\n",
    "\n",
    "    for group in sorted(data.keys()):\n",
    "        for participant in sorted(data[group].keys()):\n",
    "            p_data = data[group][participant]\n",
    "\n",
    "            row = {\n",
    "                \"グループ\": group,\n",
    "                \"参加者\": participant,\n",
    "            }\n",
    "\n",
    "            for phase in phases:\n",
    "                d = p_data.get(phase, {})\n",
    "                if d:\n",
    "                    row[f\"{phase}_correct\"] = d[\"correct\"]\n",
    "                    row[f\"{phase}_total\"] = d[\"total\"]\n",
    "                    row[f\"{phase}_rate\"] = d[\"rate\"]\n",
    "                else:\n",
    "                    row[f\"{phase}_correct\"] = None\n",
    "                    row[f\"{phase}_total\"] = None\n",
    "                    row[f\"{phase}_rate\"] = None\n",
    "\n",
    "            # 伸び計算\n",
    "            pre = p_data.get(\"pre\", {})\n",
    "            post = p_data.get(\"post\", {})\n",
    "            if pre and post:\n",
    "                row[\"伸び\"] = post[\"rate\"] - pre[\"rate\"]\n",
    "            else:\n",
    "                row[\"伸び\"] = None\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "df = create_score_dataframe(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_score_table(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    見やすい形式のスコア表を作成\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for group in sorted(data.keys()):\n",
    "        for participant in sorted(data[group].keys()):\n",
    "            p_data = data[group][participant]\n",
    "\n",
    "            def fmt(d):\n",
    "                if not d:\n",
    "                    return \"-\"\n",
    "                return f\"{d['correct']}/{d['total']} ({d['rate']:.1f}%)\"\n",
    "\n",
    "            pre = p_data.get(\"pre\", {})\n",
    "            post = p_data.get(\"post\", {})\n",
    "\n",
    "            if pre and post:\n",
    "                diff = f\"{post['rate'] - pre['rate']:+.1f}%\"\n",
    "            else:\n",
    "                diff = \"-\"\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"グループ\": group,\n",
    "                    \"参加者\": participant,\n",
    "                    \"Pre\": fmt(p_data.get(\"pre\")),\n",
    "                    \"Training1\": fmt(p_data.get(\"training1\")),\n",
    "                    \"Training2\": fmt(p_data.get(\"training2\")),\n",
    "                    \"Training3\": fmt(p_data.get(\"training3\")),\n",
    "                    \"Post\": fmt(p_data.get(\"post\")),\n",
    "                    \"伸び\": diff,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "score_table = format_score_table(data)\n",
    "score_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グループ別集計\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_summary(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    グループ別の集計（全フェーズ完了者のみ）\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    phases = [\"pre\", \"training1\", \"training2\", \"training3\", \"post\"]\n",
    "\n",
    "    for group in sorted(data.keys()):\n",
    "        totals = {phase: {\"correct\": 0, \"total\": 0} for phase in phases}\n",
    "        complete_count = 0\n",
    "\n",
    "        for participant in data[group]:\n",
    "            p_data = data[group][participant]\n",
    "\n",
    "            # 全フェーズ完了者のみ\n",
    "            if all(phase in p_data for phase in phases):\n",
    "                complete_count += 1\n",
    "                for phase in phases:\n",
    "                    totals[phase][\"correct\"] += p_data[phase][\"correct\"]\n",
    "                    totals[phase][\"total\"] += p_data[phase][\"total\"]\n",
    "\n",
    "        if complete_count > 0:\n",
    "            row = {\"グループ\": group, \"n\": complete_count}\n",
    "\n",
    "            for phase in phases:\n",
    "                c = totals[phase][\"correct\"]\n",
    "                t = totals[phase][\"total\"]\n",
    "                rate = c / t * 100 if t > 0 else 0\n",
    "                row[phase] = f\"{c}/{t} ({rate:.1f}%)\"\n",
    "                row[f\"{phase}_rate\"] = rate\n",
    "\n",
    "            row[\"伸び\"] = f\"{row['post_rate'] - row['pre_rate']:+.1f}%\"\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    display_cols = [\n",
    "        \"グループ\",\n",
    "        \"n\",\n",
    "        \"pre\",\n",
    "        \"training1\",\n",
    "        \"training2\",\n",
    "        \"training3\",\n",
    "        \"post\",\n",
    "        \"伸び\",\n",
    "    ]\n",
    "    return df[display_cols]\n",
    "\n",
    "\n",
    "group_summary = compute_group_summary(data)\n",
    "group_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参加者数サマリー\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_summary(data: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    参加者数のサマリー\n",
    "    \"\"\"\n",
    "    phases = [\"pre\", \"training1\", \"training2\", \"training3\", \"post\"]\n",
    "    rows = []\n",
    "\n",
    "    for group in sorted(data.keys()):\n",
    "        total = len(data[group])\n",
    "        complete = sum(\n",
    "            1 for p in data[group] if all(phase in data[group][p] for phase in phases)\n",
    "        )\n",
    "        rows.append(\n",
    "            {\n",
    "                \"グループ\": group,\n",
    "                \"全参加者\": total,\n",
    "                \"完了者\": complete,\n",
    "                \"未完了\": total - complete,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "participant_summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV出力\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じてCSV出力\n",
    "# output_dir = project_root / \"data\" / \"output\"\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# df.to_csv(output_dir / \"score_summary.csv\", index=False, encoding='utf-8-sig')\n",
    "# print(f\"保存先: {output_dir / 'score_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 統計分析\n",
    "\n",
    "### 1. 記述統計\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre/Post正答率と伸びをグループ別に計算\n",
    "def compute_descriptive_stats(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    記述統計を計算\n",
    "    \"\"\"\n",
    "    stats_data = {}\n",
    "\n",
    "    for group in sorted(data.keys()):\n",
    "        pre_rates = []\n",
    "        post_rates = []\n",
    "        gains = []\n",
    "\n",
    "        for participant in data[group]:\n",
    "            p_data = data[group][participant]\n",
    "            if \"pre\" in p_data and \"post\" in p_data:\n",
    "                pre = p_data[\"pre\"][\"rate\"]\n",
    "                post = p_data[\"post\"][\"rate\"]\n",
    "                pre_rates.append(pre)\n",
    "                post_rates.append(post)\n",
    "                gains.append(post - pre)\n",
    "\n",
    "        stats_data[group] = {\n",
    "            \"pre\": np.array(pre_rates),\n",
    "            \"post\": np.array(post_rates),\n",
    "            \"gain\": np.array(gains),\n",
    "            \"n\": len(pre_rates),\n",
    "        }\n",
    "\n",
    "    return stats_data\n",
    "\n",
    "\n",
    "stats_data = compute_descriptive_stats(data)\n",
    "\n",
    "# 記述統計テーブル\n",
    "desc_rows = []\n",
    "for group in sorted(stats_data.keys()):\n",
    "    d = stats_data[group]\n",
    "    desc_rows.append(\n",
    "        {\n",
    "            \"グループ\": group,\n",
    "            \"n\": d[\"n\"],\n",
    "            \"Pre M(SD)\": f\"{np.mean(d['pre']):.1f}% ({np.std(d['pre'], ddof=1):.1f}%)\",\n",
    "            \"Post M(SD)\": f\"{np.mean(d['post']):.1f}% ({np.std(d['post'], ddof=1):.1f}%)\",\n",
    "            \"伸び M(SD)\": f\"{np.mean(d['gain']):+.1f}% ({np.std(d['gain'], ddof=1):.1f}%)\",\n",
    "            \"伸び範囲\": f\"{np.min(d['gain']):+.1f}% ~ {np.max(d['gain']):+.1f}%\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "desc_df = pd.DataFrame(desc_rows)\n",
    "print(\"【記述統計】\")\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 正規性検定（Shapiro-Wilk検定）\n",
    "\n",
    "パラメトリック検定（t検定）を使用できるか確認します。\n",
    "\n",
    "- p > 0.05 → 正規性を仮定できる → t検定を使用\n",
    "- p ≤ 0.05 → 正規性を仮定できない → ノンパラメトリック検定を使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk検定\n",
    "print(\"【正規性検定 (Shapiro-Wilk)】\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "normality_results = []\n",
    "for group in sorted(stats_data.keys()):\n",
    "    d = stats_data[group]\n",
    "\n",
    "    # Pre\n",
    "    stat_pre, p_pre = stats.shapiro(d[\"pre\"])\n",
    "    # Post\n",
    "    stat_post, p_post = stats.shapiro(d[\"post\"])\n",
    "    # 伸び\n",
    "    stat_gain, p_gain = stats.shapiro(d[\"gain\"])\n",
    "\n",
    "    normality_results.append(\n",
    "        {\n",
    "            \"グループ\": group,\n",
    "            \"Pre W\": f\"{stat_pre:.3f}\",\n",
    "            \"Pre p\": f\"{p_pre:.3f}\",\n",
    "            \"Pre 正規性\": \"○\" if p_pre > 0.05 else \"×\",\n",
    "            \"Post W\": f\"{stat_post:.3f}\",\n",
    "            \"Post p\": f\"{p_post:.3f}\",\n",
    "            \"Post 正規性\": \"○\" if p_post > 0.05 else \"×\",\n",
    "            \"伸び W\": f\"{stat_gain:.3f}\",\n",
    "            \"伸び p\": f\"{p_gain:.3f}\",\n",
    "            \"伸び 正規性\": \"○\" if p_gain > 0.05 else \"×\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "norm_df = pd.DataFrame(normality_results)\n",
    "norm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 各群内の学習効果検証\n",
    "\n",
    "各群でPre→Postで有意な変化があったかを検証します。\n",
    "\n",
    "- **パラメトリック**: 対応のあるt検定 (paired t-test)\n",
    "- **ノンパラメトリック**: Wilcoxon符号順位検定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各群内の学習効果検証\n",
    "print(\"【各群内の学習効果 (Pre vs Post)】\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "within_results = []\n",
    "for group in sorted(stats_data.keys()):\n",
    "    d = stats_data[group]\n",
    "    pre = d[\"pre\"]\n",
    "    post = d[\"post\"]\n",
    "\n",
    "    # 対応のあるt検定（片側: Post > Pre）\n",
    "    t_stat, t_p = stats.ttest_rel(post, pre, alternative=\"greater\")\n",
    "\n",
    "    # Wilcoxon符号順位検定（片側: Post > Pre）\n",
    "    w_stat, w_p = stats.wilcoxon(post - pre, alternative=\"greater\")\n",
    "\n",
    "    # 効果量 (Cohen's d for paired samples)\n",
    "    diff = post - pre\n",
    "    cohens_d = np.mean(diff) / np.std(diff, ddof=1)\n",
    "\n",
    "    within_results.append(\n",
    "        {\n",
    "            \"グループ\": group,\n",
    "            \"n\": d[\"n\"],\n",
    "            \"平均差\": f\"{np.mean(diff):+.1f}%\",\n",
    "            \"t値\": f\"{t_stat:.3f}\",\n",
    "            \"t検定 p\": f\"{t_p:.3f}\",\n",
    "            \"Wilcoxon p\": f\"{w_p:.3f}\",\n",
    "            \"Cohen's d\": f\"{cohens_d:.3f}\",\n",
    "            \"効果量\": \"大\"\n",
    "            if abs(cohens_d) >= 0.8\n",
    "            else \"中\"\n",
    "            if abs(cohens_d) >= 0.5\n",
    "            else \"小\"\n",
    "            if abs(cohens_d) >= 0.2\n",
    "            else \"なし\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"\\n■ グループ {group}\")\n",
    "    print(\n",
    "        f\"  Pre → Post: {np.mean(pre):.1f}% → {np.mean(post):.1f}% (差: {np.mean(diff):+.1f}%)\"\n",
    "    )\n",
    "    print(f\"  対応のあるt検定: t = {t_stat:.3f}, p = {t_p:.3f}\")\n",
    "    print(f\"  Wilcoxon符号順位検定: p = {w_p:.3f}\")\n",
    "    print(f\"  効果量 (Cohen's d): {cohens_d:.3f}\")\n",
    "\n",
    "within_df = pd.DataFrame(within_results)\n",
    "print(\"\\n\")\n",
    "within_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 群間比較（伸びの差）\n",
    "\n",
    "A群とB群で「伸び」に有意差があるかを検証します。\n",
    "\n",
    "- **パラメトリック**: 独立t検定 (independent t-test)\n",
    "- **ノンパラメトリック**: Mann-Whitney U検定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 群間比較（伸びの差）\n",
    "print(\"【群間比較 (A群 vs B群の伸び)】\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gain_A = stats_data[\"A\"][\"gain\"]\n",
    "gain_B = stats_data[\"B\"][\"gain\"]\n",
    "\n",
    "# 独立t検定（片側: B群 > A群）\n",
    "t_stat, t_p = stats.ttest_ind(gain_A, gain_B, alternative=\"less\")\n",
    "\n",
    "# Mann-Whitney U検定（片側: B群 > A群）\n",
    "u_stat, u_p = stats.mannwhitneyu(gain_A, gain_B, alternative=\"less\")\n",
    "\n",
    "# 効果量 (Cohen's d for independent samples)\n",
    "pooled_std = np.sqrt(\n",
    "    (\n",
    "        (len(gain_A) - 1) * np.var(gain_A, ddof=1)\n",
    "        + (len(gain_B) - 1) * np.var(gain_B, ddof=1)\n",
    "    )\n",
    "    / (len(gain_A) + len(gain_B) - 2)\n",
    ")\n",
    "cohens_d = (np.mean(gain_A) - np.mean(gain_B)) / pooled_std\n",
    "\n",
    "print(f\"A群の伸び: M = {np.mean(gain_A):+.1f}%, SD = {np.std(gain_A, ddof=1):.1f}%\")\n",
    "print(f\"B群の伸び: M = {np.mean(gain_B):+.1f}%, SD = {np.std(gain_B, ddof=1):.1f}%\")\n",
    "print(f\"群間差: {np.mean(gain_A) - np.mean(gain_B):+.1f}%\")\n",
    "print()\n",
    "print(f\"独立t検定: t = {t_stat:.3f}, p = {t_p:.3f}\")\n",
    "print(f\"Mann-Whitney U検定: U = {u_stat:.1f}, p = {u_p:.3f}\")\n",
    "print(f\"効果量 (Cohen's d): {cohens_d:.3f}\")\n",
    "\n",
    "effect_size = (\n",
    "    \"大\"\n",
    "    if abs(cohens_d) >= 0.8\n",
    "    else \"中\"\n",
    "    if abs(cohens_d) >= 0.5\n",
    "    else \"小\"\n",
    "    if abs(cohens_d) >= 0.2\n",
    "    else \"なし\"\n",
    ")\n",
    "print(f\"効果量の解釈: {effect_size}\")\n",
    "\n",
    "# 結果のサマリー\n",
    "between_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"比較\": \"A群 vs B群 (伸び)\",\n",
    "            \"A群 M(SD)\": f\"{np.mean(gain_A):+.1f}% ({np.std(gain_A, ddof=1):.1f}%)\",\n",
    "            \"B群 M(SD)\": f\"{np.mean(gain_B):+.1f}% ({np.std(gain_B, ddof=1):.1f}%)\",\n",
    "            \"群間差\": f\"{np.mean(gain_A) - np.mean(gain_B):+.1f}%\",\n",
    "            \"t値\": f\"{t_stat:.3f}\",\n",
    "            \"t検定 p\": f\"{t_p:.3f}\",\n",
    "            \"U値\": f\"{u_stat:.1f}\",\n",
    "            \"Mann-Whitney p\": f\"{u_p:.3f}\",\n",
    "            \"Cohen's d\": f\"{cohens_d:.3f}\",\n",
    "            \"効果量\": effect_size,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(\"\\n\")\n",
    "between_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 結果のまとめ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果のまとめ\n",
    "print(\"=\" * 70)\n",
    "print(\"【統計分析結果のまとめ】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n■ 記述統計\")\n",
    "print(\n",
    "    f\"  A群 (n=10): Pre {np.mean(stats_data['A']['pre']):.1f}% → Post {np.mean(stats_data['A']['post']):.1f}% (伸び: {np.mean(stats_data['A']['gain']):+.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  B群 (n=10): Pre {np.mean(stats_data['B']['pre']):.1f}% → Post {np.mean(stats_data['B']['post']):.1f}% (伸び: {np.mean(stats_data['B']['gain']):+.1f}%)\"\n",
    ")\n",
    "\n",
    "print(\"\\n■ 各群内の学習効果\")\n",
    "for group in [\"A\", \"B\"]:\n",
    "    d = stats_data[group]\n",
    "    t_stat, t_p = stats.ttest_rel(d[\"post\"], d[\"pre\"], alternative=\"greater\")\n",
    "    sig = \"有意\" if t_p < 0.05 else \"有意でない\"\n",
    "    print(f\"  {group}群: t = {t_stat:.3f}, p = {t_p:.3f} → {sig}\")\n",
    "\n",
    "print(\"\\n■ 群間比較（伸びの差）\")\n",
    "t_stat, t_p = stats.ttest_ind(gain_A, gain_B, alternative=\"less\")\n",
    "sig = \"有意差あり\" if t_p < 0.05 else \"有意差なし\"\n",
    "print(f\"  独立t検定: t = {t_stat:.3f}, p = {t_p:.3f} → {sig}\")\n",
    "\n",
    "print(\"\\n■ 結論\")\n",
    "if t_p < 0.05:\n",
    "    if np.mean(gain_B) > np.mean(gain_A):\n",
    "        print(\"  B群の学習法がA群より有意に効果的であった\")\n",
    "    else:\n",
    "        print(\"  A群の学習法がB群より有意に効果的であった\")\n",
    "else:\n",
    "    print(\"  A群とB群の学習法に統計的有意差は認められなかった\")\n",
    "    print(\n",
    "        f\"  (ただし、B群の方が伸びが大きい傾向: +{np.mean(gain_B) - np.mean(gain_A):.1f}%)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 追加の統計分析\n",
    "\n",
    "### 6. 混合分散分析（Mixed ANOVA）\n",
    "\n",
    "グループ（被験者間要因）× 時点（被験者内要因）の二元配置分散分析。\n",
    "交互作用が有意であれば、「伸び方がグループ間で異なる」ことを示す。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed ANOVA用のデータ準備\n",
    "# Long format に変換\n",
    "anova_rows = []\n",
    "for group in [\"A\", \"B\"]:\n",
    "    for i, (pre, post) in enumerate(\n",
    "        zip(stats_data[group][\"pre\"], stats_data[group][\"post\"])\n",
    "    ):\n",
    "        anova_rows.append(\n",
    "            {\"subject\": f\"{group}_{i}\", \"group\": group, \"time\": \"pre\", \"score\": pre}\n",
    "        )\n",
    "        anova_rows.append(\n",
    "            {\"subject\": f\"{group}_{i}\", \"group\": group, \"time\": \"post\", \"score\": post}\n",
    "        )\n",
    "\n",
    "anova_df = pd.DataFrame(anova_rows)\n",
    "print(\"【Mixed ANOVA用データ（Long format）】\")\n",
    "print(anova_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed ANOVA (手動計算)\n",
    "# pingouin がインストールされていない場合の代替実装\n",
    "\n",
    "print(\"【混合分散分析 (Mixed ANOVA)】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# データ準備\n",
    "pre_A = stats_data[\"A\"][\"pre\"]\n",
    "post_A = stats_data[\"A\"][\"post\"]\n",
    "pre_B = stats_data[\"B\"][\"pre\"]\n",
    "post_B = stats_data[\"B\"][\"post\"]\n",
    "\n",
    "n_A, n_B = len(pre_A), len(pre_B)\n",
    "N = n_A + n_B  # 総人数\n",
    "\n",
    "# 全体平均\n",
    "grand_mean = np.mean(np.concatenate([pre_A, post_A, pre_B, post_B]))\n",
    "\n",
    "# グループ平均\n",
    "mean_A = np.mean(np.concatenate([pre_A, post_A]))\n",
    "mean_B = np.mean(np.concatenate([pre_B, post_B]))\n",
    "\n",
    "# 時点平均\n",
    "mean_pre = np.mean(np.concatenate([pre_A, pre_B]))\n",
    "mean_post = np.mean(np.concatenate([post_A, post_B]))\n",
    "\n",
    "# セル平均\n",
    "mean_A_pre = np.mean(pre_A)\n",
    "mean_A_post = np.mean(post_A)\n",
    "mean_B_pre = np.mean(pre_B)\n",
    "mean_B_post = np.mean(post_B)\n",
    "\n",
    "# 平方和の計算\n",
    "# グループ主効果 (Between-subjects)\n",
    "SS_group = 2 * (n_A * (mean_A - grand_mean) ** 2 + n_B * (mean_B - grand_mean) ** 2)\n",
    "\n",
    "# 時点主効果 (Within-subjects)\n",
    "SS_time = N * ((mean_pre - grand_mean) ** 2 + (mean_post - grand_mean) ** 2)\n",
    "\n",
    "# 交互作用\n",
    "SS_interaction = n_A * (\n",
    "    (mean_A_pre - mean_A - mean_pre + grand_mean) ** 2\n",
    "    + (mean_A_post - mean_A - mean_post + grand_mean) ** 2\n",
    ") + n_B * (\n",
    "    (mean_B_pre - mean_B - mean_pre + grand_mean) ** 2\n",
    "    + (mean_B_post - mean_B - mean_post + grand_mean) ** 2\n",
    ")\n",
    "\n",
    "# 被験者間誤差\n",
    "subject_means_A = (pre_A + post_A) / 2\n",
    "subject_means_B = (pre_B + post_B) / 2\n",
    "SS_subjects = 2 * (\n",
    "    np.sum((subject_means_A - mean_A) ** 2) + np.sum((subject_means_B - mean_B) ** 2)\n",
    ")\n",
    "\n",
    "# 被験者内誤差 (残差)\n",
    "SS_error_within = 0\n",
    "for i in range(n_A):\n",
    "    SS_error_within += (pre_A[i] - subject_means_A[i] - mean_pre + mean_A) ** 2\n",
    "    SS_error_within += (post_A[i] - subject_means_A[i] - mean_post + mean_A) ** 2\n",
    "for i in range(n_B):\n",
    "    SS_error_within += (pre_B[i] - subject_means_B[i] - mean_pre + mean_B) ** 2\n",
    "    SS_error_within += (post_B[i] - subject_means_B[i] - mean_post + mean_B) ** 2\n",
    "\n",
    "# 自由度\n",
    "df_group = 1\n",
    "df_time = 1\n",
    "df_interaction = 1\n",
    "df_subjects = N - 2  # 被験者間誤差\n",
    "df_error_within = N - 2  # 被験者内誤差\n",
    "\n",
    "# 平均平方\n",
    "MS_group = SS_group / df_group\n",
    "MS_time = SS_time / df_time\n",
    "MS_interaction = SS_interaction / df_interaction\n",
    "MS_subjects = SS_subjects / df_subjects\n",
    "MS_error_within = SS_error_within / df_error_within\n",
    "\n",
    "# F値\n",
    "F_group = MS_group / MS_subjects\n",
    "F_time = MS_time / MS_error_within\n",
    "F_interaction = MS_interaction / MS_error_within\n",
    "\n",
    "# p値\n",
    "p_group = 1 - stats.f.cdf(F_group, df_group, df_subjects)\n",
    "p_time = 1 - stats.f.cdf(F_time, df_time, df_error_within)\n",
    "p_interaction = 1 - stats.f.cdf(F_interaction, df_interaction, df_error_within)\n",
    "\n",
    "# 効果量 (partial η²)\n",
    "eta2_group = SS_group / (SS_group + SS_subjects)\n",
    "eta2_time = SS_time / (SS_time + SS_error_within)\n",
    "eta2_interaction = SS_interaction / (SS_interaction + SS_error_within)\n",
    "\n",
    "print(\"\\n■ グループ主効果 (A vs B)\")\n",
    "print(\n",
    "    f\"  F({df_group}, {df_subjects}) = {F_group:.3f}, p = {p_group:.3f}, η²p = {eta2_group:.3f}\"\n",
    ")\n",
    "print(f\"  → {'有意' if p_group < 0.05 else '有意でない'}\")\n",
    "\n",
    "print(\"\\n■ 時点主効果 (Pre vs Post)\")\n",
    "print(\n",
    "    f\"  F({df_time}, {df_error_within}) = {F_time:.3f}, p = {p_time:.3f}, η²p = {eta2_time:.3f}\"\n",
    ")\n",
    "print(f\"  → {'有意' if p_time < 0.05 else '有意でない'}\")\n",
    "\n",
    "print(\"\\n■ 交互作用 (グループ × 時点)\")\n",
    "print(\n",
    "    f\"  F({df_interaction}, {df_error_within}) = {F_interaction:.3f}, p = {p_interaction:.3f}, η²p = {eta2_interaction:.3f}\"\n",
    ")\n",
    "print(f\"  → {'有意' if p_interaction < 0.05 else '有意でない'}\")\n",
    "\n",
    "# 結果テーブル\n",
    "anova_results = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"効果\": \"グループ (A vs B)\",\n",
    "            \"SS\": f\"{SS_group:.2f}\",\n",
    "            \"df\": df_group,\n",
    "            \"MS\": f\"{MS_group:.2f}\",\n",
    "            \"F\": f\"{F_group:.3f}\",\n",
    "            \"p\": f\"{p_group:.3f}\",\n",
    "            \"η²p\": f\"{eta2_group:.3f}\",\n",
    "            \"判定\": \"有意\" if p_group < 0.05 else \"n.s.\",\n",
    "        },\n",
    "        {\n",
    "            \"効果\": \"時点 (Pre vs Post)\",\n",
    "            \"SS\": f\"{SS_time:.2f}\",\n",
    "            \"df\": df_time,\n",
    "            \"MS\": f\"{MS_time:.2f}\",\n",
    "            \"F\": f\"{F_time:.3f}\",\n",
    "            \"p\": f\"{p_time:.3f}\",\n",
    "            \"η²p\": f\"{eta2_time:.3f}\",\n",
    "            \"判定\": \"有意\" if p_time < 0.05 else \"n.s.\",\n",
    "        },\n",
    "        {\n",
    "            \"効果\": \"交互作用\",\n",
    "            \"SS\": f\"{SS_interaction:.2f}\",\n",
    "            \"df\": df_interaction,\n",
    "            \"MS\": f\"{MS_interaction:.2f}\",\n",
    "            \"F\": f\"{F_interaction:.3f}\",\n",
    "            \"p\": f\"{p_interaction:.3f}\",\n",
    "            \"η²p\": f\"{eta2_interaction:.3f}\",\n",
    "            \"判定\": \"有意\" if p_interaction < 0.05 else \"n.s.\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(\"\\n\")\n",
    "anova_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 共分散分析（ANCOVA）\n",
    "\n",
    "Preスコアを共変量として統制し、Postスコアをグループ間で比較。\n",
    "→ 事前の個人差を統制した上で、学習効果の群間差を検証できる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANCOVA (共分散分析)\n",
    "# Preスコアを共変量、Postスコアを従属変数、グループを独立変数\n",
    "\n",
    "print(\"【共分散分析 (ANCOVA)】\")\n",
    "print(\"=\" * 70)\n",
    "print(\"従属変数: Postスコア\")\n",
    "print(\"独立変数: グループ (A vs B)\")\n",
    "print(\"共変量: Preスコア\")\n",
    "print()\n",
    "\n",
    "# データ準備\n",
    "pre_all = np.concatenate([pre_A, pre_B])\n",
    "post_all = np.concatenate([post_A, post_B])\n",
    "group_all = np.array([0] * n_A + [1] * n_B)  # A=0, B=1\n",
    "\n",
    "# 回帰分析によるANCOVA\n",
    "# Model: Post = β0 + β1*Pre + β2*Group + ε\n",
    "\n",
    "# デザイン行列\n",
    "X = np.column_stack([np.ones(N), pre_all, group_all])\n",
    "y = post_all\n",
    "\n",
    "# 最小二乗法\n",
    "beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "y_pred = X @ beta\n",
    "residuals = y - y_pred\n",
    "SS_residual = np.sum(residuals**2)\n",
    "df_residual = N - 3  # N - パラメータ数\n",
    "\n",
    "# グループ効果の検定 (β2)\n",
    "# フルモデル vs 縮小モデル（グループなし）\n",
    "X_reduced = np.column_stack([np.ones(N), pre_all])\n",
    "beta_reduced = np.linalg.lstsq(X_reduced, y, rcond=None)[0]\n",
    "y_pred_reduced = X_reduced @ beta_reduced\n",
    "SS_residual_reduced = np.sum((y - y_pred_reduced) ** 2)\n",
    "\n",
    "SS_group_effect = SS_residual_reduced - SS_residual\n",
    "df_group_effect = 1\n",
    "MS_group_effect = SS_group_effect / df_group_effect\n",
    "MS_residual = SS_residual / df_residual\n",
    "\n",
    "F_ancova = MS_group_effect / MS_residual\n",
    "p_ancova = 1 - stats.f.cdf(F_ancova, df_group_effect, df_residual)\n",
    "\n",
    "# 効果量 (partial η²)\n",
    "eta2_ancova = SS_group_effect / (SS_group_effect + SS_residual)\n",
    "\n",
    "# 調整済み平均\n",
    "mean_pre_all = np.mean(pre_all)\n",
    "adj_mean_A = beta[0] + beta[1] * mean_pre_all + beta[2] * 0\n",
    "adj_mean_B = beta[0] + beta[1] * mean_pre_all + beta[2] * 1\n",
    "\n",
    "print(\"■ 回帰係数\")\n",
    "print(f\"  切片 (β0): {beta[0]:.3f}\")\n",
    "print(f\"  Pre効果 (β1): {beta[1]:.3f}\")\n",
    "print(f\"  グループ効果 (β2): {beta[2]:.3f}\")\n",
    "\n",
    "print(\"\\n■ 調整済み平均 (Preを統制)\")\n",
    "print(f\"  A群: {adj_mean_A:.1f}%\")\n",
    "print(f\"  B群: {adj_mean_B:.1f}%\")\n",
    "print(f\"  差: {adj_mean_B - adj_mean_A:+.1f}%\")\n",
    "\n",
    "print(\"\\n■ グループ効果の検定\")\n",
    "print(f\"  F({df_group_effect}, {df_residual}) = {F_ancova:.3f}, p = {p_ancova:.3f}\")\n",
    "print(f\"  η²p = {eta2_ancova:.3f}\")\n",
    "print(f\"  → {'有意' if p_ancova < 0.05 else '有意でない'}\")\n",
    "\n",
    "# 結果テーブル\n",
    "ancova_results = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"効果\": \"グループ (Preを統制)\",\n",
    "            \"調整済み平均A\": f\"{adj_mean_A:.1f}%\",\n",
    "            \"調整済み平均B\": f\"{adj_mean_B:.1f}%\",\n",
    "            \"調整済み差\": f\"{adj_mean_B - adj_mean_A:+.1f}%\",\n",
    "            \"F\": f\"{F_ancova:.3f}\",\n",
    "            \"p\": f\"{p_ancova:.3f}\",\n",
    "            \"η²p\": f\"{eta2_ancova:.3f}\",\n",
    "            \"判定\": \"有意\" if p_ancova < 0.05 else \"n.s.\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(\"\\n\")\n",
    "ancova_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 効果量の信頼区間（ブートストラップ法）\n",
    "\n",
    "Cohen's dの95%信頼区間を算出し、効果の不確実性を評価する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ブートストラップによる効果量の信頼区間\n",
    "print(\"【効果量の信頼区間 (ブートストラップ法)】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 10000\n",
    "\n",
    "\n",
    "def compute_cohens_d(x, y):\n",
    "    \"\"\"独立サンプルのCohen's d\"\"\"\n",
    "    nx, ny = len(x), len(y)\n",
    "    pooled_std = np.sqrt(\n",
    "        ((nx - 1) * np.var(x, ddof=1) + (ny - 1) * np.var(y, ddof=1)) / (nx + ny - 2)\n",
    "    )\n",
    "    return (np.mean(x) - np.mean(y)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "\n",
    "# 元のCohen's d\n",
    "original_d = compute_cohens_d(gain_A, gain_B)\n",
    "\n",
    "# ブートストラップ\n",
    "bootstrap_ds = []\n",
    "for _ in range(n_bootstrap):\n",
    "    # リサンプリング\n",
    "    idx_A = np.random.choice(len(gain_A), size=len(gain_A), replace=True)\n",
    "    idx_B = np.random.choice(len(gain_B), size=len(gain_B), replace=True)\n",
    "    boot_A = gain_A[idx_A]\n",
    "    boot_B = gain_B[idx_B]\n",
    "    bootstrap_ds.append(compute_cohens_d(boot_A, boot_B))\n",
    "\n",
    "bootstrap_ds = np.array(bootstrap_ds)\n",
    "\n",
    "# 95%信頼区間 (パーセンタイル法)\n",
    "ci_lower = np.percentile(bootstrap_ds, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_ds, 97.5)\n",
    "\n",
    "print(\"■ 群間比較 (A群 vs B群の伸び)\")\n",
    "print(f\"  Cohen's d = {original_d:.3f}\")\n",
    "print(f\"  95% CI = [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "print()\n",
    "print(f\"  解釈: 信頼区間が0を{'含む' if ci_lower <= 0 <= ci_upper else '含まない'}\")\n",
    "if ci_lower <= 0 <= ci_upper:\n",
    "    print(\"        → 効果がないという可能性を排除できない\")\n",
    "else:\n",
    "    print(\"        → 効果があると解釈できる\")\n",
    "\n",
    "# 各群内のブートストラップ\n",
    "print(\"\\n■ 各群内の学習効果\")\n",
    "for group_name, pre, post in [(\"A\", pre_A, post_A), (\"B\", pre_B, post_B)]:\n",
    "    diff = post - pre\n",
    "    original_d_within = np.mean(diff) / np.std(diff, ddof=1)\n",
    "\n",
    "    bootstrap_ds_within = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(len(diff), size=len(diff), replace=True)\n",
    "        boot_diff = diff[idx]\n",
    "        if np.std(boot_diff, ddof=1) > 0:\n",
    "            bootstrap_ds_within.append(np.mean(boot_diff) / np.std(boot_diff, ddof=1))\n",
    "\n",
    "    bootstrap_ds_within = np.array(bootstrap_ds_within)\n",
    "    ci_lower_within = np.percentile(bootstrap_ds_within, 2.5)\n",
    "    ci_upper_within = np.percentile(bootstrap_ds_within, 97.5)\n",
    "\n",
    "    print(\n",
    "        f\"  {group_name}群: d = {original_d_within:.3f}, 95% CI = [{ci_lower_within:.3f}, {ci_upper_within:.3f}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. ベイズ統計（Bayes Factor）\n",
    "\n",
    "「差がある」vs「差がない」の証拠の強さを評価。\n",
    "\n",
    "- BF10 > 3: 差がある証拠が中程度\n",
    "- BF10 > 10: 差がある証拠が強い\n",
    "- BF10 < 1/3: 差がない証拠が中程度\n",
    "- BF10 < 1/10: 差がない証拠が強い\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベイズファクター (JZS prior を使用した近似計算)\n",
    "# Rouder et al. (2009) の方法に基づく簡易実装\n",
    "\n",
    "print(\"【ベイズファクター (Bayes Factor)】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "def bayesian_t_test(x, y, r=0.707):\n",
    "    \"\"\"\n",
    "    独立サンプルのベイズt検定\n",
    "    JZS prior (Cauchy prior with scale r) を使用\n",
    "\n",
    "    Rouder et al. (2009) の近似式を使用\n",
    "    \"\"\"\n",
    "    nx, ny = len(x), len(y)\n",
    "    n = nx + ny\n",
    "\n",
    "    # t統計量\n",
    "    pooled_var = ((nx - 1) * np.var(x, ddof=1) + (ny - 1) * np.var(y, ddof=1)) / (n - 2)\n",
    "    se = np.sqrt(pooled_var * (1 / nx + 1 / ny))\n",
    "    t = (np.mean(x) - np.mean(y)) / se\n",
    "\n",
    "    df = n - 2\n",
    "\n",
    "    # BF10 の近似計算 (Wagenmakers et al., 2007 の簡易版)\n",
    "    # BF01 ≈ (1 + t²/df)^(-(df+1)/2) * sqrt(df/(df+1)) * (1 + neff*r²)^(1/2)\n",
    "    # ただし neff = nx*ny/(nx+ny)\n",
    "\n",
    "    neff = (nx * ny) / (nx + ny)\n",
    "\n",
    "    # より正確な近似: Savage-Dickey density ratio\n",
    "    # 帰無仮説下の t の密度\n",
    "    from scipy.stats import t as t_dist\n",
    "\n",
    "    # BF01 の計算 (Wetzels et al., 2011 の方法)\n",
    "    # 数値積分による計算\n",
    "    def integrand(delta, t_val, n_eff, df_val, r_scale):\n",
    "        # 尤度\n",
    "        likelihood = t_dist.pdf(t_val, df_val, loc=delta * np.sqrt(n_eff))\n",
    "        # 事前分布 (Cauchy)\n",
    "        prior = stats.cauchy.pdf(delta, scale=r_scale)\n",
    "        return likelihood * prior\n",
    "\n",
    "    from scipy.integrate import quad\n",
    "\n",
    "    # 帰無仮説下の尤度\n",
    "    likelihood_h0 = t_dist.pdf(t, df)\n",
    "\n",
    "    # 対立仮説下の尤度（周辺尤度）\n",
    "    marginal_likelihood_h1, _ = quad(\n",
    "        lambda delta: integrand(delta, t, neff, df, r), -np.inf, np.inf\n",
    "    )\n",
    "\n",
    "    # Bayes Factor\n",
    "    bf10 = marginal_likelihood_h1 / likelihood_h0\n",
    "    bf01 = 1 / bf10\n",
    "\n",
    "    return t, df, bf10, bf01\n",
    "\n",
    "\n",
    "# 群間比較\n",
    "t_val, df_val, bf10, bf01 = bayesian_t_test(gain_A, gain_B)\n",
    "\n",
    "print(\"■ 群間比較 (A群 vs B群の伸び)\")\n",
    "print(f\"  t({df_val}) = {t_val:.3f}\")\n",
    "print(f\"  BF10 = {bf10:.3f} (H1: 差がある vs H0: 差がない)\")\n",
    "print(f\"  BF01 = {bf01:.3f} (H0: 差がない vs H1: 差がある)\")\n",
    "print()\n",
    "\n",
    "# 解釈\n",
    "if bf10 > 10:\n",
    "    interpretation = \"差がある強い証拠\"\n",
    "elif bf10 > 3:\n",
    "    interpretation = \"差がある中程度の証拠\"\n",
    "elif bf10 > 1:\n",
    "    interpretation = \"差がある弱い証拠\"\n",
    "elif bf01 > 10:\n",
    "    interpretation = \"差がない強い証拠\"\n",
    "elif bf01 > 3:\n",
    "    interpretation = \"差がない中程度の証拠\"\n",
    "else:\n",
    "    interpretation = \"どちらとも言えない (inconclusive)\"\n",
    "\n",
    "print(f\"  解釈: {interpretation}\")\n",
    "\n",
    "# 各群内のベイズt検定\n",
    "print(\"\\n■ 各群内の学習効果 (Pre vs Post)\")\n",
    "for group_name, pre, post in [(\"A\", pre_A, post_A), (\"B\", pre_B, post_B)]:\n",
    "    diff = post - pre\n",
    "    n = len(diff)\n",
    "    t_within = np.mean(diff) / (np.std(diff, ddof=1) / np.sqrt(n))\n",
    "    df_within = n - 1\n",
    "\n",
    "    # 1サンプルt検定のBF\n",
    "    # 簡易計算\n",
    "    from scipy.stats import t as t_dist\n",
    "\n",
    "    likelihood_h0_within = t_dist.pdf(t_within, df_within)\n",
    "\n",
    "    def integrand_1sample(delta, t_val, n_val, df_val, r_scale=0.707):\n",
    "        likelihood = t_dist.pdf(t_val, df_val, loc=delta * np.sqrt(n_val))\n",
    "        prior = stats.cauchy.pdf(delta, scale=r_scale)\n",
    "        return likelihood * prior\n",
    "\n",
    "    marginal_h1_within, _ = quad(\n",
    "        lambda delta: integrand_1sample(delta, t_within, n, df_within), -np.inf, np.inf\n",
    "    )\n",
    "\n",
    "    bf10_within = marginal_h1_within / likelihood_h0_within\n",
    "    bf01_within = 1 / bf10_within\n",
    "\n",
    "    print(\n",
    "        f\"  {group_name}群: t({df_within}) = {t_within:.3f}, BF10 = {bf10_within:.3f}, BF01 = {bf01_within:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 天井効果・床効果の検討\n",
    "\n",
    "高得点者（Pre 90%以上）は伸びにくい可能性がある。この影響を分析する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 天井効果・床効果の検討\n",
    "print(\"【天井効果・床効果の検討】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Pre得点と伸びの相関\n",
    "all_pre = np.concatenate([pre_A, pre_B])\n",
    "all_gain = np.concatenate([gain_A, gain_B])\n",
    "\n",
    "corr, p_corr = stats.pearsonr(all_pre, all_gain)\n",
    "print(\"■ Pre得点と伸びの相関\")\n",
    "print(f\"  r = {corr:.3f}, p = {p_corr:.3f}\")\n",
    "if corr < 0 and p_corr < 0.05:\n",
    "    print(\"  → 有意な負の相関: Pre得点が高い人ほど伸びにくい（天井効果の可能性）\")\n",
    "elif corr < 0:\n",
    "    print(\"  → 負の相関傾向: Pre得点が高い人ほど伸びにくい傾向（天井効果の可能性）\")\n",
    "\n",
    "# 高得点者・低得点者の分析\n",
    "threshold_high = 85  # 高得点の閾値\n",
    "threshold_low = 65  # 低得点の閾値\n",
    "\n",
    "print(f\"\\n■ Pre得点による層別分析 (閾値: 高≥{threshold_high}%, 低≤{threshold_low}%)\")\n",
    "\n",
    "for group_name, pre, gain in [(\"A\", pre_A, gain_A), (\"B\", pre_B, gain_B)]:\n",
    "    high_mask = pre >= threshold_high\n",
    "    low_mask = pre <= threshold_low\n",
    "    mid_mask = ~high_mask & ~low_mask\n",
    "\n",
    "    print(f\"\\n  {group_name}群:\")\n",
    "    print(\n",
    "        f\"    高得点者 (≥{threshold_high}%): n={np.sum(high_mask)}, 伸び平均 = {np.mean(gain[high_mask]):+.1f}%\"\n",
    "        if np.sum(high_mask) > 0\n",
    "        else \"    高得点者: n=0\"\n",
    "    )\n",
    "    print(\n",
    "        f\"    中得点者: n={np.sum(mid_mask)}, 伸び平均 = {np.mean(gain[mid_mask]):+.1f}%\"\n",
    "        if np.sum(mid_mask) > 0\n",
    "        else \"    中得点者: n=0\"\n",
    "    )\n",
    "    print(\n",
    "        f\"    低得点者 (≤{threshold_low}%): n={np.sum(low_mask)}, 伸び平均 = {np.mean(gain[low_mask]):+.1f}%\"\n",
    "        if np.sum(low_mask) > 0\n",
    "        else \"    低得点者: n=0\"\n",
    "    )\n",
    "\n",
    "# 天井効果を除外した分析\n",
    "print(f\"\\n■ 高得点者 (Pre≥{threshold_high}%) を除外した分析\")\n",
    "mask_A_no_ceiling = pre_A < threshold_high\n",
    "mask_B_no_ceiling = pre_B < threshold_high\n",
    "\n",
    "gain_A_no_ceiling = gain_A[mask_A_no_ceiling]\n",
    "gain_B_no_ceiling = gain_B[mask_B_no_ceiling]\n",
    "\n",
    "if len(gain_A_no_ceiling) > 1 and len(gain_B_no_ceiling) > 1:\n",
    "    print(\n",
    "        f\"  A群: n={len(gain_A_no_ceiling)}, 伸び平均 = {np.mean(gain_A_no_ceiling):+.1f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  B群: n={len(gain_B_no_ceiling)}, 伸び平均 = {np.mean(gain_B_no_ceiling):+.1f}%\"\n",
    "    )\n",
    "\n",
    "    t_no_ceiling, p_no_ceiling = stats.ttest_ind(gain_A_no_ceiling, gain_B_no_ceiling, alternative=\"less\")\n",
    "    print(f\"  独立t検定: t = {t_no_ceiling:.3f}, p = {p_no_ceiling:.3f}\")\n",
    "else:\n",
    "    print(\"  除外後のサンプルサイズが小さすぎます\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 統計分析の総合まとめ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計分析の総合まとめ\n",
    "print(\"=\" * 70)\n",
    "print(\"【統計分析の総合まとめ】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│  分析手法              │  結果                    │  結論          │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│  1. 記述統計           │  A群: +1.0%, B群: +3.5%  │  B群が大きい   │\n",
    "│  2. 対応のあるt検定    │  両群ともp > 0.05        │  有意でない    │\n",
    "│  3. 独立t検定          │  p = 0.667               │  有意差なし    │\n",
    "│  4. Mann-Whitney U     │  p = 0.536               │  有意差なし    │\n",
    "│  5. 混合ANOVA          │  交互作用 p > 0.05       │  有意でない    │\n",
    "│  6. ANCOVA             │  p > 0.05                │  有意差なし    │\n",
    "│  7. ブートストラップ   │  95%CI が 0 を含む       │  効果不確実    │\n",
    "│  8. ベイズファクター   │  BF01 > 1                │  差なしを支持  │\n",
    "│  9. 天井効果           │  高得点者は伸びにくい    │  分析に注意    │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "print(\"■ 総合結論\")\n",
    "print(\"  ・A群とB群の学習法に統計的有意差は認められなかった\")\n",
    "print(\"  ・ベイズ分析では「差がない」ことを支持する証拠がある\")\n",
    "print(\"  ・B群の方が伸びが大きい傾向 (+2.5%) があるが、有意ではない\")\n",
    "print()\n",
    "print(\"■ 注意点\")\n",
    "print(\"  ・サンプルサイズが小さい (各群n=10) ため、検出力が低い可能性\")\n",
    "print(\"  ・天井効果により高得点者の伸びが制限されている可能性\")\n",
    "print(\"  ・より大きなサンプルサイズでの追試が望ましい\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 有意差が見られなかった原因の分析\n",
    "\n",
    "### 12. 検出力分析（Power Analysis）\n",
    "\n",
    "現在のサンプルサイズ（各群n=10）で、どの程度の効果を検出できるかを分析する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import nct  # 非心t分布\n",
    "\n",
    "# 検出力分析 (Power Analysis)\n",
    "print(\"【検出力分析 (Power Analysis)】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "def power_t_test_ind(n1, n2, d, alpha=0.05):\n",
    "    \"\"\"\n",
    "    独立t検定の検出力を計算\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n1, n2 : int - 各群のサンプルサイズ\n",
    "    d : float - 効果量 (Cohen's d)\n",
    "    alpha : float - 有意水準\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    power : float - 検出力 (1 - β)\n",
    "    \"\"\"\n",
    "    df = n1 + n2 - 2\n",
    "    # 非心度パラメータ\n",
    "    ncp = d * np.sqrt((n1 * n2) / (n1 + n2))\n",
    "    # 臨界値\n",
    "    t_crit = stats.t.ppf(1 - alpha / 2, df)\n",
    "    # 検出力 = 1 - β\n",
    "    power = 1 - nct.cdf(t_crit, df, ncp) + nct.cdf(-t_crit, df, ncp)\n",
    "    return power\n",
    "\n",
    "\n",
    "def required_sample_size(d, power=0.80, alpha=0.05):\n",
    "    \"\"\"\n",
    "    目標検出力を達成するために必要なサンプルサイズを計算\n",
    "    \"\"\"\n",
    "    for n in range(5, 1000):\n",
    "        if power_t_test_ind(n, n, d, alpha) >= power:\n",
    "            return n\n",
    "    return \">1000\"\n",
    "\n",
    "\n",
    "# 現在のデータ\n",
    "n_current = 10\n",
    "d_observed = abs(compute_cohens_d(gain_A, gain_B))  # 0.196\n",
    "\n",
    "print(\"■ 現在の状況\")\n",
    "print(f\"  サンプルサイズ: 各群 n = {n_current}\")\n",
    "print(f\"  観測された効果量: Cohen's d = {d_observed:.3f}\")\n",
    "print(\"  有意水準: α = 0.05\")\n",
    "\n",
    "# 現在の検出力\n",
    "power_current = power_t_test_ind(n_current, n_current, d_observed)\n",
    "print(\"\\n■ 現在の検出力\")\n",
    "print(f\"  検出力 (1-β) = {power_current:.3f} ({power_current * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"  → 観測された効果 (d={d_observed:.3f}) を検出できる確率は {power_current * 100:.1f}%\"\n",
    ")\n",
    "\n",
    "# 様々な効果量での検出力\n",
    "print(\"\\n■ 効果量別の検出力 (n=10)\")\n",
    "effect_sizes = [0.2, 0.5, 0.8, 1.0, 1.2]\n",
    "for d in effect_sizes:\n",
    "    p = power_t_test_ind(n_current, n_current, d)\n",
    "    label = \"小\" if d == 0.2 else \"中\" if d == 0.5 else \"大\" if d == 0.8 else \"\"\n",
    "    print(f\"  d = {d:.1f} ({label}): 検出力 = {p:.3f} ({p * 100:.1f}%)\")\n",
    "\n",
    "# 80%検出力に必要なサンプルサイズ\n",
    "print(\"\\n■ 80%検出力を達成するために必要なサンプルサイズ\")\n",
    "for d in [0.2, 0.5, 0.8, d_observed]:\n",
    "    n_req = required_sample_size(d)\n",
    "    label = \"小\" if d == 0.2 else \"中\" if d == 0.5 else \"大\" if d == 0.8 else \"観測値\"\n",
    "    print(f\"  d = {d:.3f} ({label}): 各群 n = {n_req}\")\n",
    "\n",
    "# 検出力曲線のデータ\n",
    "print(\"\\n■ サンプルサイズと検出力の関係 (d=0.5, 中程度の効果)\")\n",
    "sample_sizes = [10, 20, 30, 50, 100]\n",
    "print(\"  n\\t検出力\")\n",
    "for n in sample_sizes:\n",
    "    p = power_t_test_ind(n, n, 0.5)\n",
    "    print(f\"  {n}\\t{p:.3f} ({p * 100:.1f}%)\")\n",
    "\n",
    "# 結論\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"【検出力分析の結論】\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "1. 現在の検出力は非常に低い ({power_current * 100:.1f}%)\n",
    "   → 実際に効果があっても検出できない可能性が高い\n",
    "\n",
    "2. 観測された効果量 (d={d_observed:.3f}) を80%の確率で検出するには\n",
    "   各群 n={required_sample_size(d_observed)} が必要\n",
    "\n",
    "3. 中程度の効果 (d=0.5) を検出するには各群 n={required_sample_size(0.5)} が必要\n",
    "\n",
    "4. 現在のn=10では、大きな効果 (d≥0.8) しか検出できない\n",
    "   → 検出力 = {power_t_test_ind(10, 10, 0.8) * 100:.1f}%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. 個人差・ばらつきの詳細分析\n",
    "\n",
    "個人差の大きさと分布を詳しく分析し、有意差が見られなかった原因を探る。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 個人差・ばらつきの詳細分析\n",
    "print(\"【個人差・ばらつきの詳細分析】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. 基本的なばらつき指標\n",
    "print(\"\\n■ 伸びのばらつき指標\")\n",
    "for group_name, gain in [('A', gain_A), ('B', gain_B)]:\n",
    "    print(f\"\\n  {group_name}群:\")\n",
    "    print(f\"    平均 (M): {np.mean(gain):+.1f}%\")\n",
    "    print(f\"    標準偏差 (SD): {np.std(gain, ddof=1):.1f}%\")\n",
    "    print(f\"    範囲: {np.min(gain):+.1f}% ~ {np.max(gain):+.1f}%\")\n",
    "    print(f\"    四分位範囲 (IQR): {np.percentile(gain, 25):.1f}% ~ {np.percentile(gain, 75):.1f}%\")\n",
    "    print(f\"    変動係数 (CV): {np.std(gain, ddof=1) / abs(np.mean(gain)) * 100:.1f}%\" if np.mean(gain) != 0 else \"    変動係数 (CV): N/A\")\n",
    "\n",
    "# 2. 伸びの分布分析\n",
    "print(\"\\n\\n■ 伸びの分布\")\n",
    "print(\"  \" + \"-\" * 50)\n",
    "bins = [(-30, -20), (-20, -10), (-10, 0), (0, 10), (10, 20), (20, 30)]\n",
    "print(f\"  {'範囲':<15} {'A群':>8} {'B群':>8}\")\n",
    "print(\"  \" + \"-\" * 50)\n",
    "for low, high in bins:\n",
    "    count_A = np.sum((gain_A > low) & (gain_A <= high))\n",
    "    count_B = np.sum((gain_B > low) & (gain_B <= high))\n",
    "    label = f\"{low:+d}% ~ {high:+d}%\"\n",
    "    bar_A = \"█\" * count_A\n",
    "    bar_B = \"█\" * count_B\n",
    "    print(f\"  {label:<15} {count_A:>3} {bar_A:<5} {count_B:>3} {bar_B:<5}\")\n",
    "\n",
    "# 3. 個人別の詳細\n",
    "print(\"\\n\\n■ 参加者別の伸び（ソート済み）\")\n",
    "print(\"\\n  A群:\")\n",
    "sorted_A = sorted(zip(gain_A, range(len(gain_A))), key=lambda x: x[0])\n",
    "for g, i in sorted_A:\n",
    "    bar = \"+\" * int(max(0, g/5)) if g >= 0 else \"-\" * int(abs(g/5))\n",
    "    print(f\"    参加者{i+1:2d}: {g:+6.1f}% {bar}\")\n",
    "\n",
    "print(\"\\n  B群:\")\n",
    "sorted_B = sorted(zip(gain_B, range(len(gain_B))), key=lambda x: x[0])\n",
    "for g, i in sorted_B:\n",
    "    bar = \"+\" * int(max(0, g/5)) if g >= 0 else \"-\" * int(abs(g/5))\n",
    "    print(f\"    参加者{i+1:2d}: {g:+6.1f}% {bar}\")\n",
    "\n",
    "# 4. 伸びた人・伸びなかった人の分析\n",
    "print(\"\\n\\n■ 伸びのカテゴリ別分析\")\n",
    "categories = [\n",
    "    (\"大幅低下\", lambda x: x <= -10),\n",
    "    (\"やや低下\", lambda x: (x > -10) & (x < 0)),\n",
    "    (\"変化なし\", lambda x: x == 0),\n",
    "    (\"やや上昇\", lambda x: (x > 0) & (x < 10)),\n",
    "    (\"大幅上昇\", lambda x: x >= 10)\n",
    "]\n",
    "\n",
    "print(\"  \" + \"-\" * 60)\n",
    "print(f\"  {'カテゴリ':<12} {'A群':>8} {'B群':>8} {'合計':>8}\")\n",
    "print(\"  \" + \"-\" * 60)\n",
    "for cat_name, condition in categories:\n",
    "    count_A = np.sum(condition(gain_A))\n",
    "    count_B = np.sum(condition(gain_B))\n",
    "    print(f\"  {cat_name:<12} {count_A:>8} {count_B:>8} {count_A + count_B:>8}\")\n",
    "\n",
    "# 5. Signal-to-Noise Ratio\n",
    "print(\"\\n\\n■ シグナル対ノイズ比 (Signal-to-Noise Ratio)\")\n",
    "mean_diff = np.mean(gain_B) - np.mean(gain_A)  # 群間差（シグナル）\n",
    "pooled_sd = np.sqrt((np.var(gain_A, ddof=1) + np.var(gain_B, ddof=1)) / 2)  # プールSD（ノイズ）\n",
    "snr = abs(mean_diff) / pooled_sd\n",
    "\n",
    "print(f\"  群間差（シグナル）: {mean_diff:+.1f}%\")\n",
    "print(f\"  群内SD（ノイズ）: {pooled_sd:.1f}%\")\n",
    "print(f\"  SNR = |シグナル| / ノイズ = {snr:.3f}\")\n",
    "print(f\"\\n  解釈: SNRが低い（{snr:.3f} < 1）ため、\")\n",
    "print(\"        群間差が個人差のノイズに埋もれている\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回帰分析\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# 6. Pre得点と伸びの関係（詳細）\n",
    "print(\"【Pre得点と伸びの関係（詳細分析）】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 全体\n",
    "slope, intercept, r_value, p_value, std_err = linregress(all_pre, all_gain)\n",
    "print(\"\\n■ 全体の回帰分析\")\n",
    "print(f\"  回帰式: 伸び = {slope:.3f} × Pre + {intercept:.2f}\")\n",
    "print(f\"  相関係数 r = {r_value:.3f}\")\n",
    "print(f\"  決定係数 R² = {r_value**2:.3f}\")\n",
    "print(f\"  p値 = {p_value:.4f}\")\n",
    "\n",
    "# 群別\n",
    "print(\"\\n■ 群別の回帰分析\")\n",
    "for group_name, pre, gain in [('A', pre_A, gain_A), ('B', pre_B, gain_B)]:\n",
    "    slope_g, intercept_g, r_g, p_g, _ = linregress(pre, gain)\n",
    "    print(f\"\\n  {group_name}群:\")\n",
    "    print(f\"    回帰式: 伸び = {slope_g:.3f} × Pre + {intercept_g:.2f}\")\n",
    "    print(f\"    r = {r_g:.3f}, R² = {r_g**2:.3f}, p = {p_g:.3f}\")\n",
    "\n",
    "# 予測される伸び（Pre得点別）\n",
    "print(\"\\n■ Pre得点別の予測される伸び（全体回帰式より）\")\n",
    "pre_levels = [50, 60, 70, 80, 90, 100]\n",
    "print(\"  Pre得点\\t予測伸び\")\n",
    "for pre_level in pre_levels:\n",
    "    predicted_gain = slope * pre_level + intercept\n",
    "    print(f\"  {pre_level}%\\t\\t{predicted_gain:+.1f}%\")\n",
    "\n",
    "# 天井効果の影響の定量化\n",
    "print(\"\\n■ 天井効果の影響\")\n",
    "# Preが高い人（85%以上）を除いた場合の群間比較\n",
    "high_threshold = 85\n",
    "mask_A = pre_A < high_threshold\n",
    "mask_B = pre_B < high_threshold\n",
    "\n",
    "print(f\"  高得点者 (Pre≥{high_threshold}%) を除外:\")\n",
    "print(f\"    A群: n={np.sum(mask_A)}, 伸び = {np.mean(gain_A[mask_A]):+.1f}% (SD={np.std(gain_A[mask_A], ddof=1):.1f}%)\")\n",
    "print(f\"    B群: n={np.sum(mask_B)}, 伸び = {np.mean(gain_B[mask_B]):+.1f}% (SD={np.std(gain_B[mask_B], ddof=1):.1f}%)\")\n",
    "\n",
    "if np.sum(mask_A) > 1 and np.sum(mask_B) > 1:\n",
    "    t_excl, p_excl = stats.ttest_ind(gain_A[mask_A], gain_B[mask_B], alternative=\"less\")\n",
    "    d_excl = (np.mean(gain_A[mask_A]) - np.mean(gain_B[mask_B])) / np.sqrt(\n",
    "        ((np.sum(mask_A)-1)*np.var(gain_A[mask_A], ddof=1) + \n",
    "         (np.sum(mask_B)-1)*np.var(gain_B[mask_B], ddof=1)) / \n",
    "        (np.sum(mask_A) + np.sum(mask_B) - 2))\n",
    "    print(f\"    t検定: t = {t_excl:.3f}, p = {p_excl:.3f}\")\n",
    "    print(f\"    Cohen's d = {d_excl:.3f}\")\n",
    "\n",
    "# 低得点者のみの分析\n",
    "low_threshold = 70\n",
    "mask_A_low = pre_A <= low_threshold\n",
    "mask_B_low = pre_B <= low_threshold\n",
    "\n",
    "print(f\"\\n  低得点者 (Pre≤{low_threshold}%) のみ:\")\n",
    "print(f\"    A群: n={np.sum(mask_A_low)}, 伸び = {np.mean(gain_A[mask_A_low]):+.1f}% (SD={np.std(gain_A[mask_A_low], ddof=1):.1f}%)\")\n",
    "print(f\"    B群: n={np.sum(mask_B_low)}, 伸び = {np.mean(gain_B[mask_B_low]):+.1f}% (SD={np.std(gain_B[mask_B_low], ddof=1):.1f}%)\")\n",
    "\n",
    "if np.sum(mask_A_low) > 1 and np.sum(mask_B_low) > 1:\n",
    "    t_low, p_low = stats.ttest_ind(gain_A[mask_A_low], gain_B[mask_B_low], alternative=\"less\")\n",
    "    print(f\"    t検定: t = {t_low:.3f}, p = {p_low:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. 有意差が見られなかった原因の総合まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有意差が見られなかった原因の総合まとめ\n",
    "print(\"=\" * 70)\n",
    "print(\"【有意差が見られなかった原因の総合まとめ】\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 計算値の取得\n",
    "power_current = power_t_test_ind(10, 10, abs(compute_cohens_d(gain_A, gain_B)))\n",
    "snr = abs(np.mean(gain_B) - np.mean(gain_A)) / np.sqrt((np.var(gain_A, ddof=1) + np.var(gain_B, ddof=1)) / 2)\n",
    "corr, _ = stats.pearsonr(all_pre, all_gain)\n",
    "\n",
    "print(\"\"\"\n",
    "┌────────────────────────────────────────────────────────────────────────┐\n",
    "│                      有意差が見られなかった原因                         │\n",
    "├────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                        │\n",
    "│  【原因1】検出力不足（最も重要）                                        │\n",
    "│  ─────────────────────────────────────────────────────────────────────│\"\"\")\n",
    "print(f\"│    ・現在の検出力: {power_current*100:.1f}% （推奨: 80%以上）                          │\")\n",
    "print(f\"│    ・観測された効果量 d={abs(compute_cohens_d(gain_A, gain_B)):.3f} を検出するには各群n={required_sample_size(abs(compute_cohens_d(gain_A, gain_B)))}必要   │\")\n",
    "print(\"\"\"│    ・現在のn=10では大きな効果(d≥0.8)しか検出できない                 │\n",
    "│                                                                        │\n",
    "│  【原因2】個人差が大きい                                                │\n",
    "│  ─────────────────────────────────────────────────────────────────────│\"\"\")\n",
    "print(f\"│    ・群内標準偏差: A群={np.std(gain_A, ddof=1):.1f}%, B群={np.std(gain_B, ddof=1):.1f}%                        │\")\n",
    "print(f\"│    ・群間差（シグナル）: {np.mean(gain_B) - np.mean(gain_A):+.1f}%                                   │\")\n",
    "print(f\"│    ・SNR = {snr:.3f} （シグナルがノイズに埋もれている）                   │\")\n",
    "print(\"\"\"│                                                                        │\n",
    "│  【原因3】天井効果                                                      │\n",
    "│  ─────────────────────────────────────────────────────────────────────│\"\"\")\n",
    "print(f\"│    ・Pre得点と伸びの相関: r = {corr:.3f} （有意な負の相関）               │\")\n",
    "print(\"\"\"│    ・高得点者（Pre≥85%）は伸びにくい傾向                              │\n",
    "│    ・Pre平均が両群とも70%以上と高く、伸びる余地が限定的                 │\n",
    "│                                                                        │\n",
    "│  【原因4】そもそも効果が小さい可能性                                    │\n",
    "│  ─────────────────────────────────────────────────────────────────────│\n",
    "│    ・ベイズ分析では「差がない」を支持 (BF01 > 1)                        │\n",
    "│    ・AとBの学習法に本質的な差がない可能性も考慮すべき                   │\n",
    "│                                                                        │\n",
    "└────────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "print(\"【推奨される対策】\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. サンプルサイズの増加\n",
    "   → 中程度の効果(d=0.5)を検出するには各群n=64が必要\n",
    "   → 観測された効果(d=0.196)を検出するには各群n=410が必要\n",
    "\n",
    "2. 参加者の選定基準の見直し\n",
    "   → Pre得点が低い参加者（60-70%）を対象にすることで天井効果を回避\n",
    "   → 伸びる余地のある参加者で効果を検証\n",
    "\n",
    "3. 測定精度の向上\n",
    "   → テスト問題数を増やす（現在20問→40問など）\n",
    "   → 個人差のノイズを減らす\n",
    "\n",
    "4. 効果の再検討\n",
    "   → ベイズ分析の結果も踏まえ、本当に効果があるのか理論的に再検討\n",
    "   → 他の指標（解答時間、視線データ）での効果も確認\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スロープグラフ（Pre → Post 正答数の変化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'Hiragino Sans'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "group_colors = {\"A\": \"#4C72B0\", \"B\": \"#DD8452\"}\n",
    "titles = {\"A\": \"比較群\", \"B\": \"実験群\"}\n",
    "axes = {\"A\": ax2, \"B\": ax1}\n",
    "\n",
    "for group in [\"A\", \"B\"]:\n",
    "    ax = axes[group]\n",
    "    gc = group_colors[group]\n",
    "    participants = sorted(\n",
    "        p for p in data[group]\n",
    "        if \"pre\" in data[group][p] and \"post\" in data[group][p]\n",
    "    )\n",
    "    pre_rates = []\n",
    "    post_rates = []\n",
    "\n",
    "    for participant in participants:\n",
    "        p_data = data[group][participant]\n",
    "        pre_r = p_data[\"pre\"][\"rate\"]\n",
    "        post_r = p_data[\"post\"][\"rate\"]\n",
    "        pre_rates.append(pre_r)\n",
    "        post_rates.append(post_r)\n",
    "        ax.plot(\n",
    "            [0, 1], [pre_r, post_r],\n",
    "            color=gc, alpha=0.3, linewidth=1.2,\n",
    "            marker=\"o\", markersize=4, zorder=2,\n",
    "        )\n",
    "\n",
    "    # 群平均線\n",
    "    mean_pre = np.mean(pre_rates)\n",
    "    mean_post = np.mean(post_rates)\n",
    "    ax.plot(\n",
    "        [0, 1], [mean_pre, mean_post],\n",
    "        color=gc, alpha=1.0, linewidth=3.0,\n",
    "        marker=\"o\", markersize=10, zorder=3,\n",
    "        label=\"平均\",\n",
    "    )\n",
    "    ax.annotate(\n",
    "        f\"{mean_pre:.1f}%\", (0, mean_pre),\n",
    "        textcoords=\"offset points\", xytext=(-38, 0),\n",
    "        fontsize=10, color=gc, fontweight=\"bold\", va=\"center\",\n",
    "    )\n",
    "    ax.annotate(\n",
    "        f\"{mean_post:.1f}%\", (1, mean_post),\n",
    "        textcoords=\"offset points\", xytext=(12, 0),\n",
    "        fontsize=10, color=gc, fontweight=\"bold\", va=\"center\",\n",
    "    )\n",
    "\n",
    "    # 中央の縦点線\n",
    "    ax.axvline(x=0.5, color=\"gray\", linestyle=\":\", linewidth=0.8, zorder=1)\n",
    "\n",
    "    ax.set_title(titles[group], fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([\"Pre\", \"Post\"], fontsize=12)\n",
    "    ax.set_xlim(-0.3, 1.3)\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    # 枠線: 黒で囲む\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color(\"black\")\n",
    "        spine.set_linewidth(0.8)\n",
    "    ax.tick_params(bottom=False)\n",
    "\n",
    "    # Y軸グリッド線\n",
    "    ax.yaxis.grid(True, alpha=0.3, linestyle=\"--\")\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    ax.legend(loc=\"lower right\", fontsize=10)\n",
    "\n",
    "ax1.set_ylabel(\"正答率 (%)\", fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Pre/Post テスト正答率の変化\", fontsize=15, fontweight=\"bold\", y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "output_path = project_root / \"data\" / \"output\" / \"slopegraph_pre_post.png\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(output_path, dpi=300, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "print(f\"保存完了: {output_path}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
