{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"../lib/\")\n",
    "import eyegaze as eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 設定 ==========\n",
    "group_letter = \"B\"\n",
    "participant_id = \"P001\"\n",
    "phase = \"pre\"\n",
    "\n",
    "# パス設定\n",
    "base_dir = f\"../../data/input/{group_letter}/{participant_id}/{phase}\"\n",
    "working_dir = f\"../../data/working/{group_letter}/{participant_id}/{phase}\"\n",
    "output_dir = f\"../../data/output/{group_letter}/{participant_id}/{phase}\"\n",
    "\n",
    "# eye_trackingディレクトリ（背景画像用）\n",
    "eye_tracking_base = os.path.join(base_dir, \"eye_tracking\")\n",
    "timestamp_dirs = sorted([d for d in os.listdir(eye_tracking_base) \n",
    "                         if os.path.isdir(os.path.join(eye_tracking_base, d))])\n",
    "eye_tracking_dir = os.path.join(eye_tracking_base, timestamp_dirs[-1])\n",
    "\n",
    "print(f\"Group: {group_letter}, Participant: {participant_id}, Phase: {phase}\")\n",
    "print(f\"Eye tracking dir: {eye_tracking_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 座標ファイルとfixationファイルの対応を作成\n",
    "coordinates_dir = os.path.join(base_dir, \"coordinates\")\n",
    "fixation_dir = os.path.join(working_dir, \"fixation\")\n",
    "\n",
    "# 座標ファイル一覧\n",
    "coord_files = sorted(glob.glob(os.path.join(coordinates_dir, \"question_*.json\")))\n",
    "print(f\"Found {len(coord_files)} coordinate files\")\n",
    "\n",
    "# passage_id と image_number の対応\n",
    "# pre_01 -> 003, pre_02 -> 004, ...\n",
    "segments_info = []\n",
    "for coord_file in coord_files:\n",
    "    coords = eg.loadCoordinates(coord_file)\n",
    "    passage_id = coords['coordinates']['passage_id']\n",
    "    img_num = eg.passageIdToImageNumber(passage_id)\n",
    "    \n",
    "    fixation_file = os.path.join(fixation_dir, f\"{img_num}.csv\")\n",
    "    image_file = os.path.join(eye_tracking_dir, f\"{img_num}_back.png\")\n",
    "    \n",
    "    segments_info.append({\n",
    "        'passage_id': passage_id,\n",
    "        'image_number': img_num,\n",
    "        'coord_file': coord_file,\n",
    "        'fixation_file': fixation_file,\n",
    "        'image_file': image_file,\n",
    "        'fixation_exists': os.path.exists(fixation_file)\n",
    "    })\n",
    "\n",
    "for seg in segments_info:\n",
    "    status = \"OK\" if seg['fixation_exists'] else \"MISSING\"\n",
    "    print(f\"  {seg['passage_id']} ({seg['image_number']}): {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル: 1つのセグメントでAOI分析\n",
    "sample_seg = segments_info[0]\n",
    "print(f\"Analyzing: {sample_seg['passage_id']}\")\n",
    "\n",
    "# 座標データ読み込み\n",
    "coords = eg.loadCoordinates(sample_seg['coord_file'])\n",
    "\n",
    "# AOI抽出（全レベル）\n",
    "aois = eg.extractAOIs(coords, levels=[\"paragraph\", \"sentence\", \"word\", \"choice\", \"question\"])\n",
    "print(f\"Extracted {len(aois)} AOIs\")\n",
    "\n",
    "# レベル別集計\n",
    "for level in [\"paragraph\", \"sentence\", \"word\", \"choice\", \"question\"]:\n",
    "    count = len([a for a in aois if a['level'] == level])\n",
    "    print(f\"  {level}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixationデータ読み込み\n",
    "fixations = pd.read_csv(sample_seg['fixation_file'])\n",
    "print(f\"Loaded {len(fixations)} fixations\")\n",
    "print(fixations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOIマッチング\n",
    "matched = eg.matchFixationsToAOIs(fixations, aois)\n",
    "\n",
    "# DataFrameに変換して確認\n",
    "matched_df = pd.DataFrame(matched)\n",
    "print(f\"Matched {len(matched_df)} fixations\")\n",
    "print(\"\\nSample (first 10 rows):\")\n",
    "print(matched_df[['timestamp', 'x', 'y', 'duration', 'sentence_id', 'word_text']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文レベルの統計\n",
    "sent_stats = eg.computeAOIStatistics(matched, level=\"sentence\")\n",
    "print(\"=== Sentence-level Statistics ===\")\n",
    "print(sent_stats[['aoi_id', 'text', 'total_duration', 'fixation_count', 'revisits']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選択肢レベルの統計\n",
    "choice_stats = eg.computeAOIStatistics(matched, level=\"choice\")\n",
    "print(\"=== Choice-level Statistics ===\")\n",
    "print(choice_stats[['aoi_id', 'text', 'total_duration', 'fixation_count', 'revisits']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化: 文レベル\n",
    "eg.plotAOIWithGaze(\n",
    "    sample_seg['image_file'],\n",
    "    aois,\n",
    "    fixations,\n",
    "    level=\"sentence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化: 選択肢レベル\n",
    "eg.plotAOIWithGaze(\n",
    "    sample_seg['image_file'],\n",
    "    aois,\n",
    "    fixations,\n",
    "    level=\"choice\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全セグメントの一括処理\n",
    "all_matched = []\n",
    "all_stats = []\n",
    "\n",
    "for seg in segments_info:\n",
    "    if not seg['fixation_exists']:\n",
    "        print(f\"Skipping {seg['passage_id']}: fixation file not found\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing {seg['passage_id']}...\")\n",
    "    \n",
    "    # 座標とfixation読み込み\n",
    "    coords = eg.loadCoordinates(seg['coord_file'])\n",
    "    aois = eg.extractAOIs(coords)\n",
    "    fixations = pd.read_csv(seg['fixation_file'])\n",
    "    \n",
    "    # マッチング\n",
    "    matched = eg.matchFixationsToAOIs(fixations, aois)\n",
    "    matched_df = pd.DataFrame(matched)\n",
    "    matched_df['passage_id'] = seg['passage_id']\n",
    "    all_matched.append(matched_df)\n",
    "    \n",
    "    # 統計（文レベル）\n",
    "    sent_stats = eg.computeAOIStatistics(matched, level=\"sentence\")\n",
    "    sent_stats['passage_id'] = seg['passage_id']\n",
    "    all_stats.append(sent_stats)\n",
    "    \n",
    "    # 可視化保存\n",
    "    viz_dir = os.path.join(output_dir, \"aoi_visualization\")\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    eg.plotAOIWithGaze(\n",
    "        seg['image_file'],\n",
    "        aois,\n",
    "        fixations,\n",
    "        level=\"sentence\",\n",
    "        save_path=os.path.join(viz_dir, f\"{seg['image_number']}_sentence.png\")\n",
    "    )\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をCSVに保存\n",
    "if all_matched:\n",
    "    # 時系列データ\n",
    "    all_matched_df = pd.concat(all_matched, ignore_index=True)\n",
    "    aoi_fixations_dir = os.path.join(output_dir, \"aoi_fixations\")\n",
    "    os.makedirs(aoi_fixations_dir, exist_ok=True)\n",
    "    all_matched_df.to_csv(os.path.join(aoi_fixations_dir, \"all_fixations.csv\"), index=False)\n",
    "    print(f\"Saved {len(all_matched_df)} fixation records\")\n",
    "    \n",
    "    # 統計サマリー\n",
    "    all_stats_df = pd.concat(all_stats, ignore_index=True)\n",
    "    all_stats_df.to_csv(os.path.join(output_dir, \"aoi_statistics.csv\"), index=False)\n",
    "    print(f\"Saved statistics for {len(all_stats_df)} AOIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計サマリー表示\n",
    "if all_stats:\n",
    "    all_stats_df = pd.concat(all_stats, ignore_index=True)\n",
    "    \n",
    "    print(\"=== Overall Statistics ===\")\n",
    "    print(f\"Total sentences analyzed: {len(all_stats_df)}\")\n",
    "    print(f\"Total fixation time: {all_stats_df['total_duration'].sum():.2f}s\")\n",
    "    print(f\"Mean fixation time per sentence: {all_stats_df['total_duration'].mean():.3f}s\")\n",
    "    print(\"\\nTop 10 most viewed sentences:\")\n",
    "    print(all_stats_df.nlargest(10, 'total_duration')[['passage_id', 'aoi_id', 'text', 'total_duration', 'fixation_count']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-intro (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
